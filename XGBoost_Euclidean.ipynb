{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469f8054-4125-4c71-84a3-0b854d618114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import random \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde10824-a82c-4ebf-b616-8a95f0b57ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04f9fa8293f4943ba7ec0bd60eed2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"BTC_USDT-4h-12.json\") as f: \n",
    "    d = json.load(f) \n",
    "\n",
    "chart_df = pd.DataFrame(d) \n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "    binance = ccxt.binance() \n",
    "    dates = df[\"timestamp\"].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)):\n",
    "        date_string = binance.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string) \n",
    "    df[\"datetime\"] = timestamp\n",
    "    df = df.drop(columns={\"timestamp\"}) \n",
    "    return df \n",
    "\n",
    "chart_df = process(chart_df) \n",
    "\n",
    "hours, days, months, years = [],[],[],[] \n",
    "for dt in tqdm(chart_df[\"datetime\"]):\n",
    "        dtobj = pd.to_datetime(dt) \n",
    "        hour = dtobj.hour \n",
    "        day = dtobj.day \n",
    "        month = dtobj.month \n",
    "        year = dtobj.year \n",
    "        hours.append(hour) \n",
    "        days.append(day) \n",
    "        months.append(month) \n",
    "        years.append(year) \n",
    "\n",
    "chart_df[\"hours\"] = hours \n",
    "chart_df[\"days\"] = days  \n",
    "chart_df[\"months\"] = months \n",
    "chart_df[\"years\"] = years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3499b9-e55a-4212-b4ba-42e1d0a87ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_data(chart_df, threshold=0.0075): \n",
    "    targets = [] \n",
    "    openv = chart_df[\"open\"].values \n",
    "    close = chart_df[\"close\"].values \n",
    "    high = chart_df[\"high\"].values \n",
    "    low = chart_df[\"low\"].values  \n",
    "    volume = chart_df[\"volume\"].values \n",
    "    \n",
    "    for i in range(close.shape[0]-1):\n",
    "        high_vol = (high[i+1] - close[i]) / close[i] \n",
    "        low_vol = (low[i+1] - close[i]) / close[i] \n",
    "        if high_vol >= threshold: \n",
    "            targets.append(0) \n",
    "        elif low_vol <= -threshold:\n",
    "            targets.append(1) \n",
    "        else:\n",
    "            targets.append(2) \n",
    "        \n",
    "    targets.append(None) \n",
    "    chart_df[\"Targets\"] = targets \n",
    "    \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "    chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "    chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False) \n",
    "    chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "    chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
    "    chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "    chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "    chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "    chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "    chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"] \n",
    "    chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"]     \n",
    "    for l in tqdm(range(1, 12), position=0, leave=True): \n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "            val = chart_df[col].values \n",
    "            val_ret = [None for _ in range(l)]\n",
    "            for i in range(l, len(val)):\n",
    "                if val[i-l] == 0: \n",
    "                    ret = 1 \n",
    "                else:\n",
    "                    ret = val[i] / val[i-l]  \n",
    "                val_ret.append(ret) \n",
    "            chart_df[\"{}_change_{}\".format(col, l)] = val_ret \n",
    "\n",
    "    chart_df.dropna(inplace=True) \n",
    "    chart_df.drop(columns={\"open\", \"high\", \"low\", \"close\", \"volume\"}, inplace=True) \n",
    "    return chart_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b50bb36-c61f-4761-97ca-f0b2e180b652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ecfa165d9843de89103f206194a81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Targets', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_df = preprocess_seq_data(chart_df) \n",
    "\n",
    "sns.countplot(chart_df, x=\"Targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f53f11-1f40-4684-9282-9fb65c359130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9449, 68), (9449,), (1181, 68), (1181,), (1182, 68), (1182,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = []\n",
    "for col in chart_df.columns:\n",
    "    if col not in [\"Targets\", \"datetime\", \"years\"]:\n",
    "        train_columns.append(col)  \n",
    "\n",
    "X = chart_df[train_columns] \n",
    "Y = chart_df[\"Targets\"] \n",
    "\n",
    "train_size = int(chart_df.shape[0] * 0.8) \n",
    "val_size = int(chart_df.shape[0] * 0.1) \n",
    "\n",
    "X_train = X.iloc[:train_size] \n",
    "Y_train = Y.iloc[:train_size] \n",
    "\n",
    "X_val = X.iloc[train_size:train_size+val_size] \n",
    "Y_val = Y.iloc[train_size:train_size+val_size] \n",
    "\n",
    "X_test = X.iloc[train_size+val_size:] \n",
    "Y_test = Y.iloc[train_size+val_size:] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a66e8e-9915-4c89-8be3-0abbe48ecad4",
   "metadata": {},
   "source": [
    "From here on, we only use X_val and X_test as we collected similar (pattern matched using ED) samples for the validation and test set only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e6db34-02b5-4850-8c32-8fb09d622a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2363, 69)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.concat([X_val, Y_val], axis=1) \n",
    "test = pd.concat([X_test, Y_test], axis=1) \n",
    "\n",
    "full_df = pd.concat([val, test], axis=0) \n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfea5c7-9434-4b27-9aa1-a4e4f520033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xgb_chart_similar_dates.pkl\", \"rb\") as f: \n",
    "    similar_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad1bbb4-b8ce-47a7-9b3c-15bad6e9ac6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e2e5ed2a7045c98934d59467a0dc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comp_columns = train_columns[3:] \n",
    "\n",
    "date_chart_info = {} # date, index \n",
    "\n",
    "all_dates = chart_df.index \n",
    "\n",
    "for i in tqdm(range(len(all_dates)), position=0, leave=True): \n",
    "    date_chart_info[all_dates[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b142e-60d8-46b7-af84-adcf4821d7e8",
   "metadata": {},
   "source": [
    "## No similar patterns used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b914d41b-2c19-4aca-a984-c36a5375d70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 69), (236, 69), (237, 69))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * full_df.shape[0]) \n",
    "val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "train_df = full_df.iloc[:train_size] \n",
    "val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "test_df = full_df.iloc[train_size+val_size:] \n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8ca79c-6dcf-4e00-8126-b9dacc03e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [] \n",
    "for col in train_df.columns: \n",
    "    if col not in [\"Targets\"]: \n",
    "        train_columns.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d9472e-9282-4649-a325-4006df6ec355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 68), (1890,), (236, 68), (236,), (237, 68), (237,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df[train_columns] \n",
    "Y_train = train_df[\"Targets\"] \n",
    "\n",
    "X_val = val_df[train_columns] \n",
    "Y_val = val_df[\"Targets\"] \n",
    "\n",
    "X_test = test_df[train_columns] \n",
    "Y_test = test_df[\"Targets\"] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07eade50-878e-4794-a676-94e920c14c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:59:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07640\n",
      "[20]\tvalidation_0-mlogloss:1.06534\n",
      "[40]\tvalidation_0-mlogloss:1.15647\n",
      "[60]\tvalidation_0-mlogloss:1.19999\n",
      "[80]\tvalidation_0-mlogloss:1.25483\n",
      "[100]\tvalidation_0-mlogloss:1.28639\n",
      "[120]\tvalidation_0-mlogloss:1.31688\n",
      "[140]\tvalidation_0-mlogloss:1.33819\n",
      "[160]\tvalidation_0-mlogloss:1.36550\n",
      "[180]\tvalidation_0-mlogloss:1.39386\n",
      "[199]\tvalidation_0-mlogloss:1.40875\n",
      "accuracy : 51.89873417721519% | Weighted F1 : 0.5803859518490941\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(silent=False, \n",
    "                    n_estimators=200,\n",
    "                    class_weight=d, \n",
    "                    metric=\"logloss\",\n",
    "                    tree_method=\"gpu_hist\")\n",
    "\n",
    "clf.fit(X_train, \n",
    "        Y_train, \n",
    "        eval_set=[(X_val, Y_val)],\n",
    "        verbose=20)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "cnt = 0 \n",
    "for i in range(len(Y_pred)): \n",
    "    if Y_pred[i] == Y_test[i]: \n",
    "        cnt += 1 \n",
    "        \n",
    "accuracy = cnt / len(Y_pred) * 100\n",
    "f1 = f1_score(Y_test, Y_pred, average=\"weighted\") \n",
    "\n",
    "print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3db5f-a6fa-40bb-aca3-65dc76aeb83d",
   "metadata": {},
   "source": [
    "# With similar patterns used: scores softmax normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ac033f-2311-4244-8c6e-2f15b28e58c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e39943f695240aeac46d76cd7a63142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[04:59:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08126\n",
      "[20]\tvalidation_0-mlogloss:1.07369\n",
      "[40]\tvalidation_0-mlogloss:1.11309\n",
      "[60]\tvalidation_0-mlogloss:1.18322\n",
      "[80]\tvalidation_0-mlogloss:1.24760\n",
      "[100]\tvalidation_0-mlogloss:1.30006\n",
      "[120]\tvalidation_0-mlogloss:1.35072\n",
      "[140]\tvalidation_0-mlogloss:1.37543\n",
      "[160]\tvalidation_0-mlogloss:1.40297\n",
      "[180]\tvalidation_0-mlogloss:1.42553\n",
      "[199]\tvalidation_0-mlogloss:1.45043\n",
      "Top 5 similar patterns used\n",
      "accuracy : 51.47679324894515% | Weighted F1 : 0.579074907155939\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce313fd548e41d78c5899efd5237051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[04:59:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08194\n",
      "[20]\tvalidation_0-mlogloss:1.08648\n",
      "[40]\tvalidation_0-mlogloss:1.13619\n",
      "[60]\tvalidation_0-mlogloss:1.16518\n",
      "[80]\tvalidation_0-mlogloss:1.20102\n",
      "[100]\tvalidation_0-mlogloss:1.26903\n",
      "[120]\tvalidation_0-mlogloss:1.28212\n",
      "[140]\tvalidation_0-mlogloss:1.31528\n",
      "[160]\tvalidation_0-mlogloss:1.33572\n",
      "[180]\tvalidation_0-mlogloss:1.34898\n",
      "[199]\tvalidation_0-mlogloss:1.36623\n",
      "Top 10 similar patterns used\n",
      "accuracy : 55.27426160337553% | Weighted F1 : 0.6106559960091001\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b846aca60f141579259ad8269bd984e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[04:59:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07292\n",
      "[20]\tvalidation_0-mlogloss:1.04152\n",
      "[40]\tvalidation_0-mlogloss:1.10092\n",
      "[60]\tvalidation_0-mlogloss:1.15260\n",
      "[80]\tvalidation_0-mlogloss:1.20740\n",
      "[100]\tvalidation_0-mlogloss:1.25578\n",
      "[120]\tvalidation_0-mlogloss:1.28231\n",
      "[140]\tvalidation_0-mlogloss:1.31214\n",
      "[160]\tvalidation_0-mlogloss:1.33510\n",
      "[180]\tvalidation_0-mlogloss:1.35297\n",
      "[199]\tvalidation_0-mlogloss:1.36994\n",
      "Top 15 similar patterns used\n",
      "accuracy : 56.118143459915615% | Weighted F1 : 0.614334297376847\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640bf1e8971345589269692a8edc5b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[04:59:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07409\n",
      "[20]\tvalidation_0-mlogloss:1.04501\n",
      "[40]\tvalidation_0-mlogloss:1.08860\n",
      "[60]\tvalidation_0-mlogloss:1.14167\n",
      "[80]\tvalidation_0-mlogloss:1.19649\n",
      "[100]\tvalidation_0-mlogloss:1.24529\n",
      "[120]\tvalidation_0-mlogloss:1.28344\n",
      "[140]\tvalidation_0-mlogloss:1.31020\n",
      "[160]\tvalidation_0-mlogloss:1.32971\n",
      "[180]\tvalidation_0-mlogloss:1.34798\n",
      "[199]\tvalidation_0-mlogloss:1.35730\n",
      "Top 20 similar patterns used\n",
      "accuracy : 52.320675105485236% | Weighted F1 : 0.5828969450843487\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2943600563434bb6a19411a63188aa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[04:59:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07904\n",
      "[20]\tvalidation_0-mlogloss:1.02529\n",
      "[40]\tvalidation_0-mlogloss:1.08587\n",
      "[60]\tvalidation_0-mlogloss:1.11599\n",
      "[80]\tvalidation_0-mlogloss:1.17233\n",
      "[100]\tvalidation_0-mlogloss:1.21847\n",
      "[120]\tvalidation_0-mlogloss:1.26782\n",
      "[140]\tvalidation_0-mlogloss:1.29516\n",
      "[160]\tvalidation_0-mlogloss:1.32109\n",
      "[180]\tvalidation_0-mlogloss:1.33676\n",
      "[199]\tvalidation_0-mlogloss:1.35522\n",
      "Top 25 similar patterns used\n",
      "accuracy : 56.540084388185655% | Weighted F1 : 0.6223925255892645\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771f3ce3397d4b05bba11b0cd481f9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[04:59:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:59:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07426\n",
      "[20]\tvalidation_0-mlogloss:1.04350\n",
      "[40]\tvalidation_0-mlogloss:1.08745\n",
      "[60]\tvalidation_0-mlogloss:1.13487\n",
      "[80]\tvalidation_0-mlogloss:1.18298\n",
      "[100]\tvalidation_0-mlogloss:1.23528\n",
      "[120]\tvalidation_0-mlogloss:1.26381\n",
      "[140]\tvalidation_0-mlogloss:1.28810\n",
      "[160]\tvalidation_0-mlogloss:1.30457\n",
      "[180]\tvalidation_0-mlogloss:1.32620\n",
      "[199]\tvalidation_0-mlogloss:1.34857\n",
      "Top 30 similar patterns used\n",
      "accuracy : 56.118143459915615% | Weighted F1 : 0.6162931706104605\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "accuracies, f1_scores = [], [] \n",
    "\n",
    "for topk in [5, 10, 15, 20, 25, 30]: \n",
    "    long_cnt, short_cnt, hold_cnt = [], [], [] \n",
    "    vote_accuracy = 0 \n",
    "    for key, value in tqdm(similar_dict.items(), position=0, leave=True): \n",
    "        query_idx = date_chart_info[key] \n",
    "        query_target = chart_df[\"Targets\"].iloc[query_idx] \n",
    "        cnt_map = {0:0, 1:0, 2:0} \n",
    "        for i in range(len(value[:topk])): \n",
    "            candidate_idx = date_chart_info[value[i][0]] \n",
    "            candidate_target = chart_df[\"Targets\"].iloc[candidate_idx] \n",
    "            cnt_map[candidate_target] += 1 \n",
    "        softmaxed = nn.Softmax()(torch.tensor([cnt_map[0], cnt_map[1], cnt_map[2]]).float()) \n",
    "        long_cnt.append(softmaxed[0].item()) \n",
    "        short_cnt.append(softmaxed[1].item()) \n",
    "        hold_cnt.append(softmaxed[2].item()) \n",
    "    \n",
    "    full_df[\"long_vote\"] = long_cnt \n",
    "    full_df[\"short_vote\"] = short_cnt \n",
    "    full_df[\"hold_vote\"] = hold_cnt \n",
    "        \n",
    "    train_size = int(0.8 * full_df.shape[0]) \n",
    "    val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "    train_df = full_df.iloc[:train_size] \n",
    "    val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "    test_df = full_df.iloc[train_size+val_size:]  \n",
    "    \n",
    "    train_columns = [] \n",
    "    for col in train_df.columns: \n",
    "        if col not in [\"Targets\"]: \n",
    "            train_columns.append(col) \n",
    "            \n",
    "    X_train = train_df[train_columns] \n",
    "    Y_train = train_df[\"Targets\"] \n",
    "\n",
    "    X_val = val_df[train_columns] \n",
    "    Y_val = val_df[\"Targets\"] \n",
    "\n",
    "    X_test = test_df[train_columns] \n",
    "    Y_test = test_df[\"Targets\"] \n",
    "    \n",
    "    print(\"printing dataframe shapes\") \n",
    "    print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "    \n",
    "    FE_clf = XGBClassifier(silent=False, \n",
    "                           n_estimators=200,\n",
    "                           class_weight=d, \n",
    "                           metric=\"logloss\",\n",
    "                           tree_method=\"gpu_hist\")  \n",
    "    FE_clf.fit(X_train, \n",
    "               Y_train, \n",
    "               eval_set=[(X_val, Y_val)],\n",
    "               verbose=20) \n",
    "    \n",
    "    \n",
    "    Y_pred = FE_clf.predict(X_test)\n",
    "\n",
    "    cnt = 0 \n",
    "    for i in range(len(Y_pred)): \n",
    "        if Y_pred[i] == Y_test[i]: \n",
    "            cnt += 1 \n",
    "\n",
    "    accuracy = cnt / len(Y_pred) * 100\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Top {topk} similar patterns used\") \n",
    "    print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") \n",
    "    print(\"=\"*50) \n",
    "    \n",
    "    accuracies.append(accuracy) \n",
    "    f1_scores.append(f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff74bb5-84e1-40bd-90c8-99fcba746cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 54.64135021097047% | mean weighted F1: 0.6042746403043268\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies) \n",
    "mean_f1 = np.mean(f1_scores) \n",
    "\n",
    "print(f\"mean accuracy: {mean_accuracy}% | mean weighted F1: {mean_f1}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81189b8e-d341-4af5-8540-5cfa9bc42c6a",
   "metadata": {},
   "source": [
    "# With similar patterns used: raw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90edf9e9-5eeb-4d99-96ca-5d5e2b1ee4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1e1764625540b3a322d8b6a7379d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[05:03:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:03:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08016\n",
      "[20]\tvalidation_0-mlogloss:1.04557\n",
      "[40]\tvalidation_0-mlogloss:1.10123\n",
      "[60]\tvalidation_0-mlogloss:1.14593\n",
      "[80]\tvalidation_0-mlogloss:1.20097\n",
      "[100]\tvalidation_0-mlogloss:1.24320\n",
      "[120]\tvalidation_0-mlogloss:1.28034\n",
      "[140]\tvalidation_0-mlogloss:1.30004\n",
      "[160]\tvalidation_0-mlogloss:1.32848\n",
      "[180]\tvalidation_0-mlogloss:1.34854\n",
      "[199]\tvalidation_0-mlogloss:1.37254\n",
      "Top 5 similar patterns used\n",
      "accuracy : 53.16455696202531% | Weighted F1 : 0.590540612522681\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7910a92970424b9af6a759a93ec0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[05:03:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:03:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07575\n",
      "[20]\tvalidation_0-mlogloss:1.05644\n",
      "[40]\tvalidation_0-mlogloss:1.12613\n",
      "[60]\tvalidation_0-mlogloss:1.17420\n",
      "[80]\tvalidation_0-mlogloss:1.21602\n",
      "[100]\tvalidation_0-mlogloss:1.25982\n",
      "[120]\tvalidation_0-mlogloss:1.30324\n",
      "[140]\tvalidation_0-mlogloss:1.33536\n",
      "[160]\tvalidation_0-mlogloss:1.36549\n",
      "[180]\tvalidation_0-mlogloss:1.39074\n",
      "[199]\tvalidation_0-mlogloss:1.41387\n",
      "Top 10 similar patterns used\n",
      "accuracy : 58.22784810126582% | Weighted F1 : 0.6297074872851155\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77be8b20d3014a918c5183915b14c36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[05:03:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:03:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07408\n",
      "[20]\tvalidation_0-mlogloss:1.06174\n",
      "[40]\tvalidation_0-mlogloss:1.09349\n",
      "[60]\tvalidation_0-mlogloss:1.13897\n",
      "[80]\tvalidation_0-mlogloss:1.19855\n",
      "[100]\tvalidation_0-mlogloss:1.24766\n",
      "[120]\tvalidation_0-mlogloss:1.28402\n",
      "[140]\tvalidation_0-mlogloss:1.31626\n",
      "[160]\tvalidation_0-mlogloss:1.34197\n",
      "[180]\tvalidation_0-mlogloss:1.37618\n",
      "[199]\tvalidation_0-mlogloss:1.39057\n",
      "Top 15 similar patterns used\n",
      "accuracy : 49.36708860759494% | Weighted F1 : 0.5543579930187156\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86ec318dd3b443299f9914e21d621e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[05:03:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:03:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07337\n",
      "[20]\tvalidation_0-mlogloss:1.04690\n",
      "[40]\tvalidation_0-mlogloss:1.09684\n",
      "[60]\tvalidation_0-mlogloss:1.13578\n",
      "[80]\tvalidation_0-mlogloss:1.17869\n",
      "[100]\tvalidation_0-mlogloss:1.22590\n",
      "[120]\tvalidation_0-mlogloss:1.26053\n",
      "[140]\tvalidation_0-mlogloss:1.28688\n",
      "[160]\tvalidation_0-mlogloss:1.31230\n",
      "[180]\tvalidation_0-mlogloss:1.33921\n",
      "[199]\tvalidation_0-mlogloss:1.35789\n",
      "Top 20 similar patterns used\n",
      "accuracy : 56.540084388185655% | Weighted F1 : 0.6197243638814056\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd8477a623c48edbd32d1cd9b700507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[05:03:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:03:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07511\n",
      "[20]\tvalidation_0-mlogloss:1.05763\n",
      "[40]\tvalidation_0-mlogloss:1.12502\n",
      "[60]\tvalidation_0-mlogloss:1.20318\n",
      "[80]\tvalidation_0-mlogloss:1.24249\n",
      "[100]\tvalidation_0-mlogloss:1.29328\n",
      "[120]\tvalidation_0-mlogloss:1.34054\n",
      "[140]\tvalidation_0-mlogloss:1.37518\n",
      "[160]\tvalidation_0-mlogloss:1.39880\n",
      "[180]\tvalidation_0-mlogloss:1.41611\n",
      "[199]\tvalidation_0-mlogloss:1.43553\n",
      "Top 25 similar patterns used\n",
      "accuracy : 52.742616033755276% | Weighted F1 : 0.5866998294711927\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d6fdebba0a4135b87e1ebda5c7cc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[05:03:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:03:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07666\n",
      "[20]\tvalidation_0-mlogloss:1.06147\n",
      "[40]\tvalidation_0-mlogloss:1.08689\n",
      "[60]\tvalidation_0-mlogloss:1.12219\n",
      "[80]\tvalidation_0-mlogloss:1.15512\n",
      "[100]\tvalidation_0-mlogloss:1.19314\n",
      "[120]\tvalidation_0-mlogloss:1.21938\n",
      "[140]\tvalidation_0-mlogloss:1.24468\n",
      "[160]\tvalidation_0-mlogloss:1.26325\n",
      "[180]\tvalidation_0-mlogloss:1.29552\n",
      "[199]\tvalidation_0-mlogloss:1.32422\n",
      "Top 30 similar patterns used\n",
      "accuracy : 54.008438818565395% | Weighted F1 : 0.5972856999842446\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "accuracies, f1_scores = [], [] \n",
    "\n",
    "for topk in [5, 10, 15, 20, 25, 30]: \n",
    "    long_cnt, short_cnt, hold_cnt = [], [], [] \n",
    "    vote_accuracy = 0 \n",
    "    for key, value in tqdm(similar_dict.items(), position=0, leave=True): \n",
    "        query_idx = date_chart_info[key] \n",
    "        query_target = chart_df[\"Targets\"].iloc[query_idx] \n",
    "        cnt_map = {0:0, 1:0, 2:0} \n",
    "        for i in range(len(value[:topk])): \n",
    "            candidate_idx = date_chart_info[value[i][0]] \n",
    "            candidate_target = chart_df[\"Targets\"].iloc[candidate_idx] \n",
    "            cnt_map[candidate_target] += 1 \n",
    "        long_cnt.append(cnt_map[0]) \n",
    "        short_cnt.append(cnt_map[1]) \n",
    "        hold_cnt.append(cnt_map[2]) \n",
    "    \n",
    "    full_df[\"long_vote\"] = long_cnt \n",
    "    full_df[\"short_vote\"] = short_cnt \n",
    "    full_df[\"hold_vote\"] = hold_cnt \n",
    "        \n",
    "    train_size = int(0.8 * full_df.shape[0]) \n",
    "    val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "    train_df = full_df.iloc[:train_size] \n",
    "    val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "    test_df = full_df.iloc[train_size+val_size:]  \n",
    "    \n",
    "    train_columns = [] \n",
    "    for col in train_df.columns: \n",
    "        if col not in [\"Targets\"]: \n",
    "            train_columns.append(col) \n",
    "            \n",
    "    X_train = train_df[train_columns] \n",
    "    Y_train = train_df[\"Targets\"] \n",
    "\n",
    "    X_val = val_df[train_columns] \n",
    "    Y_val = val_df[\"Targets\"] \n",
    "\n",
    "    X_test = test_df[train_columns] \n",
    "    Y_test = test_df[\"Targets\"] \n",
    "    \n",
    "    print(\"printing dataframe shapes\") \n",
    "    print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "    \n",
    "    FE_clf = XGBClassifier(silent=False, \n",
    "                           n_estimators=200,\n",
    "                           class_weight=d, \n",
    "                           metric=\"logloss\",\n",
    "                           tree_method=\"gpu_hist\")  \n",
    "    FE_clf.fit(X_train, \n",
    "               Y_train, \n",
    "               eval_set=[(X_val, Y_val)],\n",
    "               verbose=20) \n",
    "    \n",
    "    \n",
    "    Y_pred = FE_clf.predict(X_test)\n",
    "\n",
    "    cnt = 0 \n",
    "    for i in range(len(Y_pred)): \n",
    "        if Y_pred[i] == Y_test[i]: \n",
    "            cnt += 1 \n",
    "\n",
    "    accuracy = cnt / len(Y_pred) * 100\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Top {topk} similar patterns used\") \n",
    "    print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") \n",
    "    print(\"=\"*50) \n",
    "    \n",
    "    accuracies.append(accuracy) \n",
    "    f1_scores.append(f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc30751-fe8a-4209-8acc-14bcd8310343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 54.0084388185654% | mean weighted F1: 0.5963859976938924\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies) \n",
    "mean_f1 = np.mean(f1_scores) \n",
    "\n",
    "print(f\"mean accuracy: {mean_accuracy}% | mean weighted F1: {mean_f1}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b3bc5-a5b6-4d82-9851-fea589479f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
