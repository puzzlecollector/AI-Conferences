{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826a52d2-4b2d-4804-b139-7f9d7ed50a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import random \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59917706-2402-4b4d-b2db-b3330ae19824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618757a28c1448aeabc74e30f33fe0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"BTC_USDT-4h-12.json\") as f: \n",
    "    d = json.load(f) \n",
    "\n",
    "chart_df = pd.DataFrame(d) \n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "    binance = ccxt.binance() \n",
    "    dates = df[\"timestamp\"].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)):\n",
    "        date_string = binance.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string) \n",
    "    df[\"datetime\"] = timestamp\n",
    "    df = df.drop(columns={\"timestamp\"}) \n",
    "    return df \n",
    "\n",
    "chart_df = process(chart_df) \n",
    "\n",
    "hours, days, months, years = [],[],[],[] \n",
    "for dt in tqdm(chart_df[\"datetime\"]):\n",
    "        dtobj = pd.to_datetime(dt) \n",
    "        hour = dtobj.hour \n",
    "        day = dtobj.day \n",
    "        month = dtobj.month \n",
    "        year = dtobj.year \n",
    "        hours.append(hour) \n",
    "        days.append(day) \n",
    "        months.append(month) \n",
    "        years.append(year) \n",
    "\n",
    "chart_df[\"hours\"] = hours \n",
    "chart_df[\"days\"] = days  \n",
    "chart_df[\"months\"] = months \n",
    "chart_df[\"years\"] = years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3b16c0-86ff-4435-9874-6dc384306d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_data(chart_df, threshold=0.0075): \n",
    "    targets = [] \n",
    "    openv = chart_df[\"open\"].values \n",
    "    close = chart_df[\"close\"].values \n",
    "    high = chart_df[\"high\"].values \n",
    "    low = chart_df[\"low\"].values  \n",
    "    volume = chart_df[\"volume\"].values \n",
    "    \n",
    "    for i in range(close.shape[0]-1):\n",
    "        high_vol = (high[i+1] - close[i]) / close[i] \n",
    "        low_vol = (low[i+1] - close[i]) / close[i] \n",
    "        if high_vol >= threshold: \n",
    "            targets.append(0) \n",
    "        elif low_vol <= -threshold:\n",
    "            targets.append(1) \n",
    "        else:\n",
    "            targets.append(2) \n",
    "        \n",
    "    targets.append(None) \n",
    "    chart_df[\"Targets\"] = targets \n",
    "    \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "    chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "    chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False) \n",
    "    chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "    chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
    "    chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "    chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "    chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "    chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "    chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"] \n",
    "    chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"]     \n",
    "    for l in tqdm(range(1, 12), position=0, leave=True): \n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "            val = chart_df[col].values \n",
    "            val_ret = [None for _ in range(l)]\n",
    "            for i in range(l, len(val)):\n",
    "                if val[i-l] == 0: \n",
    "                    ret = 1 \n",
    "                else:\n",
    "                    ret = val[i] / val[i-l]  \n",
    "                val_ret.append(ret) \n",
    "            chart_df[\"{}_change_{}\".format(col, l)] = val_ret \n",
    "\n",
    "    chart_df.dropna(inplace=True) \n",
    "    chart_df.drop(columns={\"open\", \"high\", \"low\", \"close\", \"volume\"}, inplace=True) \n",
    "    return chart_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f81dea-06af-4703-ba9e-8c268d2b6b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0454c7353282413ea2b15df7ecde0326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Targets', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_df = preprocess_seq_data(chart_df) \n",
    "\n",
    "sns.countplot(chart_df, x=\"Targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5850c9cf-9f40-4604-b5c5-c808680e0dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9449, 68), (9449,), (1181, 68), (1181,), (1182, 68), (1182,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = []\n",
    "for col in chart_df.columns:\n",
    "    if col not in [\"Targets\", \"datetime\", \"years\"]:\n",
    "        train_columns.append(col)  \n",
    "\n",
    "X = chart_df[train_columns] \n",
    "Y = chart_df[\"Targets\"] \n",
    "\n",
    "train_size = int(chart_df.shape[0] * 0.8) \n",
    "val_size = int(chart_df.shape[0] * 0.1) \n",
    "\n",
    "X_train = X.iloc[:train_size] \n",
    "Y_train = Y.iloc[:train_size] \n",
    "\n",
    "X_val = X.iloc[train_size:train_size+val_size] \n",
    "Y_val = Y.iloc[train_size:train_size+val_size] \n",
    "\n",
    "X_test = X.iloc[train_size+val_size:] \n",
    "Y_test = Y.iloc[train_size+val_size:] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d307669-168c-43cf-a6d3-4cb194465a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2363, 69)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.concat([X_val, Y_val], axis=1) \n",
    "test = pd.concat([X_test, Y_test], axis=1) \n",
    "\n",
    "full_df = pd.concat([val, test], axis=0) \n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c765519-9e6b-4815-be5a-e9e03f29ce83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346590ca01bb4e918eebfeecef9dc9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comp_columns = train_columns[3:] \n",
    "\n",
    "date_chart_info = {} # date, index \n",
    "\n",
    "all_dates = chart_df.index \n",
    "\n",
    "for i in tqdm(range(len(all_dates)), position=0, leave=True): \n",
    "    date_chart_info[all_dates[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb18669-5dfc-49d7-bb0b-7cf2c09538cb",
   "metadata": {},
   "source": [
    "# No Similar Patterns Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd70fa2-00a8-43f9-8d1a-11103d810186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 69), (236, 69), (237, 69))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * full_df.shape[0]) \n",
    "val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "train_df = full_df.iloc[:train_size] \n",
    "val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "test_df = full_df.iloc[train_size+val_size:] \n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f6d09a-984b-4af2-9f99-c9910f5bb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [] \n",
    "for col in train_df.columns: \n",
    "    if col not in [\"Targets\"]: \n",
    "        train_columns.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53cc9d1-77ca-4f0c-a095-ac512afb5aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 68), (1890,), (236, 68), (236,), (237, 68), (237,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df[train_columns] \n",
    "Y_train = train_df[\"Targets\"] \n",
    "\n",
    "X_val = val_df[train_columns] \n",
    "Y_val = val_df[\"Targets\"] \n",
    "\n",
    "X_test = test_df[train_columns] \n",
    "Y_test = test_df[\"Targets\"] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6a2628-5b47-4747-88da-f74524911d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:31:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:31:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07640\n",
      "[20]\tvalidation_0-mlogloss:1.06534\n",
      "[40]\tvalidation_0-mlogloss:1.15647\n",
      "[60]\tvalidation_0-mlogloss:1.19999\n",
      "[80]\tvalidation_0-mlogloss:1.25483\n",
      "[100]\tvalidation_0-mlogloss:1.28639\n",
      "[120]\tvalidation_0-mlogloss:1.31688\n",
      "[140]\tvalidation_0-mlogloss:1.33819\n",
      "[160]\tvalidation_0-mlogloss:1.36550\n",
      "[180]\tvalidation_0-mlogloss:1.39386\n",
      "[199]\tvalidation_0-mlogloss:1.40875\n",
      "accuracy : 51.89873417721519% | Weighted F1 : 0.5803859518490941\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(silent=False, \n",
    "                    n_estimators=200,\n",
    "                    class_weight=d, \n",
    "                    metric=\"logloss\",\n",
    "                    tree_method=\"gpu_hist\")\n",
    "\n",
    "clf.fit(X_train, \n",
    "        Y_train, \n",
    "        eval_set=[(X_val, Y_val)],\n",
    "        verbose=20)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "cnt = 0 \n",
    "for i in range(len(Y_pred)): \n",
    "    if Y_pred[i] == Y_test[i]: \n",
    "        cnt += 1 \n",
    "        \n",
    "accuracy = cnt / len(Y_pred) * 100\n",
    "f1 = f1_score(Y_test, Y_pred, average=\"weighted\") \n",
    "\n",
    "print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd9040-40e4-477a-b1ac-d04de0e6a098",
   "metadata": {},
   "source": [
    "# With random patterns used: scores softmax normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78cbb1e6-1d93-4f80-9fec-47ec6965c092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e598eb6f0c449ef85bcddfb4ac9a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:59:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:59:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[07:59:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:00:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:00:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:01:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:01:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "top5_acc, top10_acc, top15_acc, top20_acc, top25_acc, top30_acc = [], [], [], [], [], [] \n",
    "top5_f1, top10_f1, top15_f1, top20_f1, top25_f1, top30_f1 = [], [], [], [], [], [] \n",
    "\n",
    "for idx in tqdm(range(10), position=0, leave=True): \n",
    "    with open(f\"random_dates/random_similar_dates_{idx+1}.pkl\", \"rb\") as f: \n",
    "        similar_dict = pickle.load(f)\n",
    "        \n",
    "    for topk in [5, 10, 15, 20, 25, 30]: \n",
    "        long_cnt, short_cnt, hold_cnt = [], [], [] \n",
    "        vote_accuracy = 0 \n",
    "        for key, value in similar_dict.items(): \n",
    "            query_idx = date_chart_info[key] \n",
    "            query_target = chart_df[\"Targets\"].iloc[query_idx] \n",
    "            cnt_map = {0:0, 1:0, 2:0} \n",
    "            for i in range(len(value[:topk])): \n",
    "                candidate_idx = date_chart_info[value[i]] \n",
    "                candidate_target = chart_df[\"Targets\"].iloc[candidate_idx] \n",
    "                cnt_map[candidate_target] += 1 \n",
    "            softmaxed = nn.Softmax()(torch.tensor([cnt_map[0], cnt_map[1], cnt_map[2]]).float()) \n",
    "            long_cnt.append(softmaxed[0].item()) \n",
    "            short_cnt.append(softmaxed[1].item()) \n",
    "            hold_cnt.append(softmaxed[2].item()) \n",
    "\n",
    "        full_df[\"long_vote\"] = long_cnt \n",
    "        full_df[\"short_vote\"] = short_cnt \n",
    "        full_df[\"hold_vote\"] = hold_cnt \n",
    "\n",
    "        train_size = int(0.8 * full_df.shape[0]) \n",
    "        val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "        train_df = full_df.iloc[:train_size] \n",
    "        val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "        test_df = full_df.iloc[train_size+val_size:]  \n",
    "\n",
    "        train_columns = [] \n",
    "        for col in train_df.columns: \n",
    "            if col not in [\"Targets\"]: \n",
    "                train_columns.append(col) \n",
    "\n",
    "        X_train = train_df[train_columns] \n",
    "        Y_train = train_df[\"Targets\"] \n",
    "\n",
    "        X_val = val_df[train_columns] \n",
    "        Y_val = val_df[\"Targets\"] \n",
    "\n",
    "        X_test = test_df[train_columns] \n",
    "        Y_test = test_df[\"Targets\"] \n",
    "\n",
    "        #print(\"printing dataframe shapes\") \n",
    "        #print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "\n",
    "        FE_clf = XGBClassifier(silent=False, \n",
    "                               n_estimators=200,\n",
    "                               class_weight=d, \n",
    "                               metric=\"logloss\",\n",
    "                               tree_method=\"gpu_hist\")  \n",
    "        FE_clf.fit(X_train, \n",
    "                   Y_train, \n",
    "                   eval_set=[(X_val, Y_val)],\n",
    "                   verbose=0) \n",
    "\n",
    "\n",
    "        Y_pred = FE_clf.predict(X_test)\n",
    "\n",
    "        cnt = 0 \n",
    "        for i in range(len(Y_pred)): \n",
    "            if Y_pred[i] == Y_test[i]: \n",
    "                cnt += 1 \n",
    "\n",
    "        accuracy = cnt / len(Y_pred) * 100\n",
    "        f1 = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "\n",
    "        #print(f\"Top {topk} similar patterns used\") \n",
    "        #print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") \n",
    "        #print(\"=\"*50) \n",
    "\n",
    "        if topk == 5: \n",
    "            top5_acc.append(accuracy) \n",
    "            top5_f1.append(f1) \n",
    "        elif topk == 10: \n",
    "            top10_acc.append(accuracy) \n",
    "            top10_f1.append(f1) \n",
    "        elif topk == 15:\n",
    "            top15_acc.append(accuracy) \n",
    "            top15_f1.append(f1) \n",
    "        elif topk == 20: \n",
    "            top20_acc.append(accuracy) \n",
    "            top20_f1.append(f1) \n",
    "        elif topk == 25: \n",
    "            top25_acc.append(accuracy) \n",
    "            top25_f1.append(f1) \n",
    "        elif topk == 30: \n",
    "            top30_acc.append(accuracy) \n",
    "            top30_f1.append(f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a35fc9a-461c-43ba-8a06-6eb0dc00a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.080168776371316, 53.670886075949376, 54.64135021097046, 54.599156118143455, 54.0084388185654, 55.0210970464135]\n",
      "\n",
      "\n",
      "\n",
      "[0.5888610981652179, 0.592317484947055, 0.6033843090993363, 0.601936938742102, 0.5967010889241243, 0.6053254569041236]\n",
      "\n",
      "\n",
      "\n",
      "mean accuracy: 54.17018284106893% | mean weighted F1: 0.5980877294636598\n"
     ]
    }
   ],
   "source": [
    "mu5, f5 = np.mean(top5_acc), np.mean(top5_f1) \n",
    "\n",
    "mu10, f10 = np.mean(top10_acc), np.mean(top10_f1)\n",
    "\n",
    "mu15, f15 = np.mean(top15_acc), np.mean(top15_f1)\n",
    "\n",
    "mu20, f20 = np.mean(top20_acc), np.mean(top20_f1)\n",
    "\n",
    "mu25, f25 = np.mean(top25_acc), np.mean(top25_f1) \n",
    "\n",
    "mu30, f30 = np.mean(top30_acc), np.mean(top30_f1)\n",
    "\n",
    "\n",
    "mus = [mu5, mu10, mu15, mu20, mu25, mu30] \n",
    "fs = [f5, f10, f15, f20, f25, f30]\n",
    "\n",
    "print(mus) \n",
    "\n",
    "print()\n",
    "print() \n",
    "print() \n",
    "print(fs) \n",
    "\n",
    "mean_accuracy = np.mean(mus) \n",
    "mean_f1 = np.mean(fs) \n",
    "\n",
    "print()\n",
    "print() \n",
    "print()\n",
    "print(f\"mean accuracy: {mean_accuracy}% | mean weighted F1: {mean_f1}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b45b8-a03b-4aae-b71a-dfa8d4c12e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5435c8-b76d-4c4b-870a-5c32ed33cb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
