{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d7197a-6746-4842-93e0-28ad8b783d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45a865504bd418abb91b9d0d1e4d429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e653aa9f3aeb41f794d7c13c11a92afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9842882351154fefba2b9f2b5646d636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4147, 23, 2, 1]) torch.Size([4147, 6, 1, 1]) torch.Size([4147, 23, 3]) torch.Size([4147, 6, 3]) torch.Size([4147, 6])\n",
      "<All keys matched successfully>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import pickle\n",
    "\n",
    "def one_hot(x, dims, gpu = True):\n",
    "    out = []\n",
    "    batch_size = x.shape[0]\n",
    "    seq_len = x.shape[1]\n",
    "    \n",
    "    if(not gpu):\n",
    "        dtype = torch.FloatTensor\n",
    "    else:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    \n",
    "    # print(\"Converting to one hot vector\")\n",
    "    for i in range(0, x.shape[-1]): # get rid of tqdm for training \n",
    "        x_ = x[:,:,i].byte().cpu().long().unsqueeze(-1)\n",
    "        o = torch.zeros([batch_size, seq_len, dims[i]]).long()\n",
    "\n",
    "        o.scatter_(-1, x_,  1)\n",
    "        out.append(o.type(dtype))\n",
    "    return out\n",
    "\n",
    "def a_norm(Q, K): \n",
    "    m = torch.matmul(Q, K.transpose(2,1).float()) \n",
    "    m /= torch.sqrt(torch.tensor(Q.shape[-1]).float()) \n",
    "    return torch.softmax(m, -1) \n",
    "\n",
    "def attention(Q, K, V): \n",
    "    a = a_norm(Q, K) # (batch_size, dim_attn, seq_length) \n",
    "    return torch.matmul(a, V) # (batch_size, seq_length, seq_length) \n",
    "\n",
    "class AttentionBlock(torch.nn.Module): \n",
    "    def __init__(self, dim_val, dim_attn): \n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.value = Value(dim_val, dim_val) \n",
    "        self.key = Key(dim_val, dim_attn) \n",
    "        self.query = Query(dim_val, dim_attn) \n",
    "    \n",
    "    def forward(self, x, kv = None):\n",
    "        if kv is None:\n",
    "            # Attention with x connected to Q,K and V (For encoder)\n",
    "            return attention(self.query(x), self.key(x), self.value(x))\n",
    "        # Attention with x as Q, external vector kv as K and V (For decoder)\n",
    "        return attention(self.query(x), self.key(kv), self.value(kv))\n",
    "    \n",
    "class MultiHeadAttentionBlock(torch.nn.Module):\n",
    "    def __init__(self, dim_val, dim_attn, n_heads):\n",
    "        super(MultiHeadAttentionBlock, self).__init__()\n",
    "        self.heads = []\n",
    "        for i in range(n_heads):\n",
    "            self.heads.append(AttentionBlock(dim_val, dim_attn))\n",
    "        self.fc = nn.Linear(n_heads * dim_val, dim_val, bias = False)\n",
    "    def forward(self, x, kv = None):\n",
    "        a = []\n",
    "        for h in self.heads:\n",
    "            a.append(h(x, kv = kv))\n",
    "            \n",
    "        a = torch.stack(a, dim = -1) #combine heads\n",
    "        a = a.flatten(start_dim = 2) #flatten all head outputs\n",
    "        \n",
    "        x = self.fc(a)\n",
    "        return x\n",
    "    \n",
    "class Value(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_val):\n",
    "        super(Value, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_input, dim_val, bias = False).cuda()\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "class Key(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_attn):\n",
    "        super(Key, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_input, dim_attn, bias = False).cuda()\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "class Query(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_attn):\n",
    "        super(Query, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_input, dim_attn, bias = False).cuda()\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "def QuantileLoss(net_out, Y, q):\n",
    "    return (q * F.relu(net_out - Y)) + ((1 - q) * F.relu(Y - net_out))\n",
    "\n",
    "\n",
    "class GLU(torch.nn.Module):\n",
    "    def __init__(self, dim_input):\n",
    "        super(GLU, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_input, dim_input)\n",
    "        self.fc2 = nn.Linear(dim_input, dim_input)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc1(x)) * self.fc2(x) \n",
    "    \n",
    "class GRN(torch.nn.Module): \n",
    "    def __init__(self, dim_input, dim_out=None, n_hidden=10, dropout_r=0.1):\n",
    "        super(GRN, self).__init__() \n",
    "        if dim_out != None: \n",
    "            self.skip = nn.Linear(dim_input, dim_out) \n",
    "        else:\n",
    "            self.skip = None\n",
    "            dim_out = dim_input \n",
    "        self.fc1 = nn.Linear(dim_input, n_hidden) \n",
    "        self.fc2 = nn.Linear(n_hidden, dim_out) \n",
    "        self.dropout = nn.Dropout(dropout_r) \n",
    "        self.gate = GLU(dim_out) \n",
    "        self.norm = nn.LayerNorm(dim_out) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = F.elu(self.fc1(x))\n",
    "        a = self.dropout(self.fc2(a))\n",
    "        a = self.gate(a)\n",
    "        if self.skip != None:\n",
    "            return self.norm(self.skip(x) + a)\n",
    "        return self.norm(x + a)\n",
    "    \n",
    "class VSN(torch.nn.Module): \n",
    "    def __init__(self, n_var_cont, n_var_disc, dim_model, dropout_r=0.1): \n",
    "        super(VSN, self).__init__()\n",
    "        n_var_total = n_var_cont + len(n_var_disc)\n",
    "        # linear transformation of inputs into dmodel vectors \n",
    "        self.linearise = []\n",
    "        for i in range(n_var_cont): \n",
    "            self.linearise.append(nn.Linear(1, dim_model, bias=False).cuda()) \n",
    "        \n",
    "        self.fc = nn.Linear(1, dim_model, bias=False).cuda()     \n",
    "        # entity embeddings for discrete inputs \n",
    "        self.entity_embed = [] \n",
    "        for i in n_var_disc: \n",
    "            self.entity_embed.append(nn.Linear(i, dim_model, bias=False).cuda())  \n",
    "        \n",
    "        self.input_grn = GRN(dim_model, dropout_r = dropout_r) \n",
    "        self.vs_grn = GRN(n_var_total * dim_model, dim_out=n_var_total, dropout_r = dropout_r)\n",
    "    \n",
    "    # input (batch_size, seq_len, n_variables, input_size)\n",
    "    def forward(self, x_cont, x_disc): \n",
    "        # linearise continuous inputs \n",
    "        linearised = [] \n",
    "        for idx, fc in enumerate(self.linearise): \n",
    "            linearised.append(fc(x_cont[:,:,idx])) \n",
    "        # entity embeddings for discrete inputs \n",
    "        embedded = []\n",
    "        \n",
    "        for x, fc in zip(x_disc, self.entity_embed): \n",
    "            embedded.append(fc(x)) \n",
    "        if len(self.linearise) != 0 and len(self.entity_embed) != 0: \n",
    "            linearised = torch.stack(linearised, dim=-2) \n",
    "            embedded = torch.stack(embedded, dim=-2)    \n",
    "            vectorised_vars = torch.cat((linearised, embedded), dim=-2) # (batch_size, seq_len, dim_model, n_vars_total)\n",
    "        elif len(self.linearise) != 0 and len(self.entity_embed) == 0: \n",
    "            vectorised_vars = torch.stack(linearised, dim=-2) # (batch_size, seq_len, n_var_cont, dim_model)\n",
    "        elif len(self.entity_embed) != 0 and len(self.linearise) == 0: \n",
    "            vectorised_vars = torch.stack(embedded, dim=-2)\n",
    "        \n",
    "        # flatten everything except accross batch for variable selection weights \n",
    "        vs_weights = self.vs_grn(vectorised_vars.flatten(start_dim=2)) # (batch_size, seq_len, n_variables)\n",
    "        vs_weights = torch.softmax(vs_weights, dim=-1).unsqueeze(-1) # (batch_size, seq_len, n_variables, 1) \n",
    "        \n",
    "        # input_grn applied to every input separately \n",
    "        input_weights = self.input_grn(vectorised_vars) # (batch_size, seq_len, n_variables, dim_model)\n",
    "        \n",
    "        x = torch.sum((vs_weights * input_weights), dim = 2) \n",
    "        return x, vs_weights # returns (batch_size, seq_len, dim_model)\n",
    "    \n",
    "class LSTMLayer(torch.nn.Module): \n",
    "    def __init__(self, dim_model, n_layers = 1, dropout_r = 0.1):\n",
    "        super(LSTMLayer, self).__init__()\n",
    "        self.n_layers = n_layers \n",
    "        self.dim_model = dim_model \n",
    "        self.lstm = nn.LSTM(dim_model, dim_model, num_layers = n_layers, batch_first = True) \n",
    "        self.hidden = None\n",
    "        self.dropout = nn.Dropout(dropout_r) \n",
    "    \n",
    "    # takes input (batch_size, seq_len, dim_model)\n",
    "    def forward(self, x): \n",
    "        if self.hidden == None: \n",
    "            raise Exception(\"Call reset() to initialise LSTM Layer\") \n",
    "            \n",
    "        x, self.hidden = self.lstm(x, self.hidden) \n",
    "        x = self.dropout(x) \n",
    "        return x, self.hidden # returns (batch_size, seq_len, dim_model), hidden \n",
    "    \n",
    "    def reset(self, batch_size, gpu = True): \n",
    "        if not gpu: \n",
    "            dtype = torch.FloatTensor \n",
    "        else: \n",
    "            dtype = torch.cuda.FloatTensor\n",
    "        self.hidden = (torch.zeros([self.n_layers, batch_size, self.dim_model]).type(dtype),\n",
    "                       torch.zeros([self.n_layers, batch_size, self.dim_model]).type(dtype)) \n",
    "\n",
    "class AttentivePooling(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AttentivePooling, self).__init__()\n",
    "        self.W = nn.Linear(input_dim, 1)\n",
    "    def forward(self, x):\n",
    "        softmax = F.softmax\n",
    "        att_w = softmax(self.W(x).squeeze(-1)).unsqueeze(-1)\n",
    "        x = torch.sum(x * att_w, dim=1)\n",
    "        return x\n",
    "    \n",
    "class TFN(torch.nn.Module): \n",
    "    def __init__(self, \n",
    "                 n_var_past_cont, \n",
    "                 n_var_future_cont,\n",
    "                 n_var_past_disc, \n",
    "                 n_var_future_disc,\n",
    "                 dim_model,\n",
    "                 n_quantiles = 1, \n",
    "                 dropout_r = 0.1,\n",
    "                 n_lstm_layers = 1,\n",
    "                 n_attention_layers = 1,\n",
    "                 n_heads = 4):\n",
    "        super(TFN, self).__init__()\n",
    "        self.vs_past = VSN(n_var_past_cont, n_var_past_disc, dim_model, dropout_r = dropout_r) \n",
    "        self.vs_future = VSN(n_var_future_cont, n_var_future_disc, dim_model, dropout_r = dropout_r)\n",
    "        \n",
    "        self.enc = LSTMLayer(dim_model, dropout_r = dropout_r, n_layers = n_lstm_layers) \n",
    "        self.dec = LSTMLayer(dim_model, dropout_r = dropout_r, n_layers = n_lstm_layers) \n",
    "        \n",
    "        self.gate1 = GLU(dim_model) \n",
    "        self.norm1 = nn.LayerNorm(dim_model) \n",
    "        \n",
    "        self.static_enrich_grn = GRN(dim_model, dropout_r = dropout_r)\n",
    "        \n",
    "        self.attention = [] \n",
    "        for i in range(n_attention_layers): \n",
    "            self.attention.append([MultiHeadAttentionBlock(dim_model, dim_model, n_heads = n_heads).cuda(),\n",
    "                                   nn.LayerNorm(dim_model).cuda()]) \n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(dim_model) \n",
    "        self.positionwise_grn = GRN(dim_model, dropout_r = dropout_r) \n",
    "        self.norm3 = nn.LayerNorm(dim_model) \n",
    "        self.dropout = nn.Dropout(dropout_r) \n",
    "        self.fc_out = nn.Linear(dim_model, n_quantiles) \n",
    "        \n",
    "        # self.attentive_pooler = AttentivePooling(n_quantiles)\n",
    "        \n",
    "    # takes input (batch_size, past_seq_len, n_variables_past) \n",
    "    # and (batch_size, future_seq_len, n_variables_future) \n",
    "    def forward(self, x_past_cont, x_past_disc, x_future_cont, x_future_disc):\n",
    "        # Encoder \n",
    "        x_past, vs_weights = self.vs_past(x_past_cont, x_past_disc) \n",
    "        e, e_hidden = self.enc(x_past) \n",
    "        self.dec_hidden = e_hidden \n",
    "        e = self.dropout(e) \n",
    "        x_past = self.norm1(self.gate1(e) + x_past) \n",
    "\n",
    "        # Decoder\n",
    "        x_future, _ = self.vs_future(x_future_cont, x_future_disc) \n",
    "        d, _ = self.dec(x_future) \n",
    "        d = self.dropout(d) \n",
    "        x_future = self.norm1(self.gate1(d) + x_future) \n",
    "\n",
    "        # static enrichment\n",
    "        x = torch.cat((x_past, x_future), dim=1) # (batch_size, past_seq_len + future_seq_len, dim_model)\n",
    "        attention_res = x_future\n",
    "        x = self.static_enrich_grn(x) \n",
    "\n",
    "        # attention layer \n",
    "        a = self.attention[0][1](self.attention[0][0](x) + x) \n",
    "        for at in self.attention[1:]:\n",
    "            a = at[1](at[0](a) + a) \n",
    "        x_future = self.norm2(a[:, x_past.shape[1]:] + x_future) \n",
    "        a = self.positionwise_grn(x_future) \n",
    "        x_future = self.norm3(a + x_future + attention_res) \n",
    "        net_out = self.fc_out(x_future)  \n",
    "        # net_out = self.attentive_pooler(net_out) \n",
    "        return net_out, vs_weights \n",
    "\n",
    "    def reset(self, batch_size, gpu = True): \n",
    "        self.enc.reset(batch_size, gpu) \n",
    "        self.dec.reset(batch_size, gpu) \n",
    "        \n",
    "        \n",
    "with open(\"BTC_USDT-1h-12.json\") as f: \n",
    "        d = json.load(f) \n",
    "\n",
    "chart_df = pd.DataFrame(d) \n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "        binance = ccxt.binance() \n",
    "        dates = df[\"timestamp\"].values \n",
    "        timestamp = [] \n",
    "        for i in range(len(dates)):\n",
    "                date_string = binance.iso8601(int(dates[i])) \n",
    "                date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "                timestamp.append(date_string) \n",
    "        df[\"datetime\"] = timestamp\n",
    "        df = df.drop(columns={\"timestamp\"}) \n",
    "        return df \n",
    "\n",
    "chart_df = process(chart_df) \n",
    "\n",
    "hours, days, months, years = [],[],[],[] \n",
    "for dt in tqdm(chart_df[\"datetime\"]):\n",
    "        dtobj = pd.to_datetime(dt) \n",
    "        hour = dtobj.hour \n",
    "        day = dtobj.day \n",
    "        month = dtobj.month \n",
    "        year = dtobj.year \n",
    "        hours.append(hour) \n",
    "        days.append(day) \n",
    "        months.append(month) \n",
    "        years.append(year) \n",
    "\n",
    "chart_df[\"hours\"] = hours \n",
    "chart_df[\"days\"] = days  \n",
    "chart_df[\"months\"] = months \n",
    "chart_df[\"years\"] = years \n",
    "\n",
    "close = chart_df[\"close\"].values \n",
    "datetimes = chart_df[\"datetime\"].values \n",
    "\n",
    "lookback_window = 24\n",
    "forecast_window = 6 \n",
    "\n",
    "date_chart_df = {} \n",
    "\n",
    "for i in tqdm(range(lookback_window, len(datetimes)-forecast_window)): \n",
    "    dtobj = datetime.strptime(str(datetimes[i]), \"%Y-%m-%d %H:%M:%S\")  \n",
    "    date_chart_df[dtobj] = (close[i-lookback_window+1:i+1], close[i+1:i+1+forecast_window])\n",
    "    \n",
    "with open(\"similarity_dict_top_10.pkl\", \"rb\") as f: \n",
    "    similarity_dict = pickle.load(f) \n",
    "    \n",
    "def get_cur_label(past, future): \n",
    "    last_close = past[-1]  \n",
    "    maxhigh, minlow = np.max(future), np.min(future) \n",
    "    high_delta = (maxhigh - last_close) / last_close * 100.0 \n",
    "    low_delta = (minlow - last_close) / last_close * 100.0  \n",
    "    if high_delta >= 1.0 or low_delta <= -1.0: \n",
    "        if high_delta >= np.abs(low_delta): \n",
    "            return 0 \n",
    "        elif high_delta < np.abs(low_delta): \n",
    "            return 1 \n",
    "    else: \n",
    "        return 2 \n",
    "    \n",
    "past_cont = [] \n",
    "future_cont = [] \n",
    "past_dates = [] \n",
    "future_dates = [] \n",
    "labels = [] \n",
    "target_seqs = []\n",
    "\n",
    "for key, value in tqdm(similarity_dict.items(), position=0, leave=True): \n",
    "    past_seq = date_chart_df[key][0] \n",
    "    future_seq = date_chart_df[key][1] \n",
    "    \n",
    "    returns = [] \n",
    "    future_returns = [] \n",
    "    rets = [] \n",
    "    for i in range(1, len(past_seq)): \n",
    "        ret = past_seq[i] / past_seq[i-1] \n",
    "        rets.append(ret) \n",
    "    returns.append(rets)    \n",
    "    \n",
    "    for i in range(len(value[:1])): \n",
    "        sim_past_seq = date_chart_df[value[i]][0] \n",
    "        sim_future_seq = date_chart_df[value[i]][1] \n",
    "        sim_returns = []\n",
    "        for j in range(1, len(sim_past_seq)): \n",
    "            ret = sim_past_seq[j] / sim_past_seq[j-1] \n",
    "            sim_returns.append(ret) \n",
    "        returns.append(sim_returns) \n",
    "        sim_future_returns = [] \n",
    "        for j in range(0, len(sim_future_seq)): \n",
    "            if j == 0: \n",
    "                ret = sim_future_seq[j] / sim_past_seq[-1] \n",
    "            else: \n",
    "                ret = sim_future_seq[j] / sim_future_seq[j-1] \n",
    "            sim_future_returns.append(ret) \n",
    "        future_returns.append(sim_future_returns) \n",
    "    past_cont.append(returns) \n",
    "    future_cont.append(future_returns) \n",
    "    \n",
    "    \n",
    "    target_returns = [] \n",
    "    for i in range(0, len(future_seq)): \n",
    "        if i == 0: \n",
    "            ret = future_seq[i] / past_seq[-1] \n",
    "        else:\n",
    "            ret = future_seq[i] / future_seq[i-1] \n",
    "        target_returns.append(ret) \n",
    "    \n",
    "    target_seqs.append(target_returns) \n",
    "    \n",
    "    label = get_cur_label(past_seq, future_seq)\n",
    "    \n",
    "    labels.append(label) \n",
    "    \n",
    "    cur_date = key - timedelta(hours=22)\n",
    "    past_date, future_date = [], [] \n",
    "    for i in range(23): \n",
    "        past_date.append([cur_date.month, cur_date.day, cur_date.hour]) \n",
    "        cur_date = cur_date + timedelta(hours=1)   \n",
    "    for i in range(6):\n",
    "        future_date.append([cur_date.month, cur_date.day, cur_date.hour]) \n",
    "        cur_date = cur_date + timedelta(hours=1) \n",
    "        \n",
    "    past_dates.append(past_date) \n",
    "    future_dates.append(future_date)\n",
    "    \n",
    "past_cont = np.array(past_cont) \n",
    "future_cont = np.array(future_cont) \n",
    "\n",
    "\n",
    "past_cont = torch.tensor(past_cont).float() \n",
    "past_cont = torch.reshape(past_cont, (-1, 23, 2, 1)) \n",
    "\n",
    "future_cont = torch.tensor(future_cont).float() \n",
    "future_cont = torch.reshape(future_cont, (-1, 6, 1, 1))\n",
    "\n",
    "past_dates = torch.tensor(past_dates) \n",
    "\n",
    "future_dates = torch.tensor(future_dates) \n",
    "\n",
    "labels = torch.tensor(labels, dtype=int) \n",
    "\n",
    "target_seqs = torch.tensor(target_seqs)  \n",
    "\n",
    "\n",
    "print(past_cont.shape, future_cont.shape, past_dates.shape, future_dates.shape, target_seqs.shape) \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "model = TFN(n_var_past_cont=2, \n",
    "            n_var_future_cont=1,\n",
    "            n_var_past_disc=[13, 32, 24], \n",
    "            n_var_future_disc=[13, 32, 24], \n",
    "            dim_model=160)\n",
    "\n",
    "checkpoint = torch.load(\"1_24_FE_4.8080254600790795e-05.pt\") \n",
    "print(model.load_state_dict(checkpoint))\n",
    "\n",
    "model.to(device) \n",
    "print()\n",
    "\n",
    "train_size = int(0.8 * past_cont.shape[0]) \n",
    "val_size = int(0.1 * past_cont.shape[0]) \n",
    "\n",
    "train_past_cont = past_cont[:train_size] \n",
    "train_past_dates = past_dates[:train_size] \n",
    "train_future_cont = future_cont[:train_size] \n",
    "train_future_dates = future_dates[:train_size] \n",
    "train_labels = labels[:train_size] \n",
    "train_target_seqs = target_seqs[:train_size] \n",
    "\n",
    "val_past_cont = past_cont[train_size:train_size+val_size] \n",
    "val_past_dates = past_dates[train_size:train_size+val_size] \n",
    "val_future_cont = future_cont[train_size:train_size+val_size] \n",
    "val_future_dates = future_dates[train_size:train_size+val_size] \n",
    "val_labels = labels[train_size:train_size+val_size] \n",
    "val_target_seqs = target_seqs[train_size:train_size+val_size] \n",
    "\n",
    "test_past_cont = past_cont[train_size+val_size:] \n",
    "test_past_dates = past_dates[train_size+val_size:]  \n",
    "test_future_cont = future_cont[train_size+val_size:] \n",
    "test_future_dates = future_dates[train_size+val_size:] \n",
    "test_labels = labels[train_size+val_size:] \n",
    "test_target_seqs = target_seqs[train_size+val_size:] \n",
    "\n",
    "batch_size = 128 \n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, past_cont, past_disc, future_cont, future_disc, target_seq): \n",
    "        self.past_cont = past_cont \n",
    "        self.past_disc = past_disc \n",
    "        self.future_cont = future_cont \n",
    "        self.future_disc = future_disc \n",
    "        self.target_seq = target_seq\n",
    "    def __len__(self): \n",
    "        return len(self.past_cont) \n",
    "    def __getitem__(self, i): \n",
    "        return {\n",
    "            \"past_cont\": torch.tensor(self.past_cont[i], dtype=torch.float32), \n",
    "            \"past_disc\": torch.tensor(self.past_disc[i], dtype=torch.float32), \n",
    "            \"future_cont\": torch.tensor(self.future_cont[i], dtype=torch.float32), \n",
    "            \"future_disc\": torch.tensor(self.future_disc[i], dtype=torch.float32), \n",
    "            \"target_seq\": torch.tensor(self.target_seq[i], dtype=torch.float32), \n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(train_past_cont, train_past_dates, train_future_cont, train_future_dates, train_target_seqs) \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "val_dataset = CustomDataset(val_past_cont, val_past_dates, val_future_cont, val_future_dates, val_target_seqs) \n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "test_dataset = CustomDataset(test_past_cont, test_past_dates, test_future_cont, test_future_dates, test_target_seqs) \n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43156a4b-117e-40ae-9b57-5113edbe92cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d973fea3b1a40d3ae74d74f75bf55ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32020/2583100947.py:504: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"past_cont\": torch.tensor(self.past_cont[i], dtype=torch.float32),\n",
      "/tmp/ipykernel_32020/2583100947.py:505: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"past_disc\": torch.tensor(self.past_disc[i], dtype=torch.float32),\n",
      "/tmp/ipykernel_32020/2583100947.py:506: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"future_cont\": torch.tensor(self.future_cont[i], dtype=torch.float32),\n",
      "/tmp/ipykernel_32020/2583100947.py:507: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"future_disc\": torch.tensor(self.future_disc[i], dtype=torch.float32),\n",
      "/tmp/ipykernel_32020/2583100947.py:508: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"target_seq\": torch.tensor(self.target_seq[i], dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17586785927414894"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, gt = [], [] \n",
    "\n",
    "loss_func = nn.L1Loss() \n",
    "model.eval() \n",
    "test_loss = 0\n",
    "for step, batch in tqdm(enumerate(test_dataloader), position=0, leave=True, total=len(test_dataloader)): \n",
    "    past_cont = batch[\"past_cont\"].to(device) \n",
    "    past_disc = batch[\"past_disc\"].to(device) \n",
    "    future_cont = batch[\"future_cont\"].to(device) \n",
    "    future_disc = batch[\"future_disc\"].to(device) \n",
    "    target_seq = batch[\"target_seq\"].to(device) \n",
    "        \n",
    "    model.reset(batch_size=past_cont.shape[0], gpu=True)\n",
    "    past_disc = one_hot(past_disc, [13, 32, 24]) \n",
    "    future_disc = one_hot(future_disc, [13, 32, 24])  \n",
    "    with torch.no_grad():\n",
    "        net_out, vs_weights = model(past_cont, past_disc, future_cont, future_disc) \n",
    "    net_out = torch.reshape(net_out, (-1, forecast_window))\n",
    "    \n",
    "    for i in range(net_out.shape[0]):  \n",
    "        predictions.append(net_out[i].detach().cpu().numpy()) \n",
    "        gt.append(target_seq[i].detach().cpu().numpy()) \n",
    "        \n",
    "    loss = loss_func(net_out, target_seq)  \n",
    "    test_loss += loss.item() \n",
    "avg_test_loss = test_loss / len(test_dataloader) \n",
    "\n",
    "avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb08d67-0b1a-434d-bc63-c4729191391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.355769230769226"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0 \n",
    "\n",
    "for i in range(len(predictions)): \n",
    "    gt_returns = [] \n",
    "    for j in range(len(gt[i])): \n",
    "        if j == 0: \n",
    "            gt_returns.append(gt[i][j]) \n",
    "        else:\n",
    "            prod = 1 \n",
    "            for k in range(0, j+1): \n",
    "                prod *= gt[i][k] \n",
    "            gt_returns.append(prod) \n",
    "    pred_returns = [] \n",
    "    for j in range(len(predictions[i])): \n",
    "        if j == 0: \n",
    "            pred_returns.append(predictions[i][j]) \n",
    "        else:\n",
    "            prod = 1 \n",
    "            for k in range(0, j+1): \n",
    "                prod *= predictions[i][k] \n",
    "            pred_returns.append(prod) \n",
    "            \n",
    "    pred_short, pred_long = False, False \n",
    "    gt_short, gt_long = False, False \n",
    "    \n",
    "    for j in range(len(pred_returns)): \n",
    "        if pred_returns[j] <= 0.99:\n",
    "            pred_short = True \n",
    "        elif pred_returns[j] >= 1.01:\n",
    "            pred_long = True \n",
    "        if gt_returns[j] <= 0.99: \n",
    "            gt_short = True \n",
    "        elif gt_returns[j] >= 1.01: \n",
    "            gt_long = True \n",
    "            \n",
    "    if pred_short == True and gt_short == True: \n",
    "        cnt += 1 \n",
    "    elif pred_long == True and gt_long == True: \n",
    "        cnt += 1 \n",
    "    elif pred_long == False and gt_long == False and pred_short == False and gt_short == False: \n",
    "        cnt += 1 \n",
    "        \n",
    "cnt / len(predictions) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7265690-7c13-4ce7-8ab9-db69f8bca46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f52a37d6940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions[50], label=\"predictions\") \n",
    "plt.plot(gt[50], label=\"ground truth\") \n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d9079-322b-4e82-85fd-ef738997fcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da7764-c262-4172-84f7-e39d72384b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe78e46-f62b-4708-980f-4c05c0c6ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a81f0-fdfb-4484-95e3-96650519fb95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
