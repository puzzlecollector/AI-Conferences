{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3a9d6d-a794-48a5-be09-78cb3f8a8a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import random \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cefe627-cd7e-41f3-a726-caae9066fd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b7f815622f428386f2ac39aa186183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"BTC_USDT-4h-12.json\") as f: \n",
    "    d = json.load(f) \n",
    "\n",
    "chart_df = pd.DataFrame(d) \n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "    binance = ccxt.binance() \n",
    "    dates = df[\"timestamp\"].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)):\n",
    "        date_string = binance.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string) \n",
    "    df[\"datetime\"] = timestamp\n",
    "    df = df.drop(columns={\"timestamp\"}) \n",
    "    return df \n",
    "\n",
    "chart_df = process(chart_df) \n",
    "\n",
    "hours, days, months, years = [],[],[],[] \n",
    "for dt in tqdm(chart_df[\"datetime\"]):\n",
    "        dtobj = pd.to_datetime(dt) \n",
    "        hour = dtobj.hour \n",
    "        day = dtobj.day \n",
    "        month = dtobj.month \n",
    "        year = dtobj.year \n",
    "        hours.append(hour) \n",
    "        days.append(day) \n",
    "        months.append(month) \n",
    "        years.append(year) \n",
    "\n",
    "chart_df[\"hours\"] = hours \n",
    "chart_df[\"days\"] = days  \n",
    "chart_df[\"months\"] = months \n",
    "chart_df[\"years\"] = years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9eb669-c27b-42af-9013-67dd752ebf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_data(chart_df, threshold=0.0075): \n",
    "    targets = [] \n",
    "    openv = chart_df[\"open\"].values \n",
    "    close = chart_df[\"close\"].values \n",
    "    high = chart_df[\"high\"].values \n",
    "    low = chart_df[\"low\"].values  \n",
    "    volume = chart_df[\"volume\"].values \n",
    "    \n",
    "    for i in range(close.shape[0]-1):\n",
    "        high_vol = (high[i+1] - close[i]) / close[i] \n",
    "        low_vol = (low[i+1] - close[i]) / close[i] \n",
    "        if high_vol >= threshold: \n",
    "            targets.append(0) \n",
    "        elif low_vol <= -threshold:\n",
    "            targets.append(1) \n",
    "        else:\n",
    "            targets.append(2) \n",
    "        \n",
    "    targets.append(None) \n",
    "    chart_df[\"Targets\"] = targets \n",
    "    \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "    chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "    chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False) \n",
    "    chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "    chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
    "    chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "    chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "    chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "    chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "    chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"] \n",
    "    chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"]     \n",
    "    for l in tqdm(range(1, 12), position=0, leave=True): \n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "            val = chart_df[col].values \n",
    "            val_ret = [None for _ in range(l)]\n",
    "            for i in range(l, len(val)):\n",
    "                if val[i-l] == 0: \n",
    "                    ret = 1 \n",
    "                else:\n",
    "                    ret = val[i] / val[i-l]  \n",
    "                val_ret.append(ret) \n",
    "            chart_df[\"{}_change_{}\".format(col, l)] = val_ret \n",
    "\n",
    "    chart_df.dropna(inplace=True) \n",
    "    chart_df.drop(columns={\"open\", \"high\", \"low\", \"close\", \"volume\"}, inplace=True) \n",
    "    return chart_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f1e34f-9e65-47f2-bb90-a464522ccffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ee7d83542341718f48e2babce001f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Targets', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASBklEQVR4nO3de/DldV3H8edL1kumuSg/iXbBZWSnIkvUDSnKMZmWhS7LlDp4Y8Ot7Q9sdGosrCkSddIuEt5oKDYWuyB5Y3NM2kHKyRFkSeKaw09T2R2UjV1BM62ld3+cz9pp+f32c5b9nXN+u7/nY+bM+X7f38/3e96/OcCL7/WkqpAk6UAeM+0GJEmLn2EhSeoyLCRJXYaFJKnLsJAkdS2bdgPjcMwxx9SqVaum3YYkHVZuueWWf6+qmbmWHZFhsWrVKrZv3z7tNiTpsJLki/Mt8zCUJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSp64i8g/tgPO/1V027hSXhlj84b9otSDoE7llIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldYw2LJF9IcnuSW5Nsb7WnJtmW5J72fnSrJ8k7kswmuS3Jc4e2s6GNvyfJhnH2LEl6pEnsWfxEVZ1SVWva/IXA9VW1Gri+zQOcBaxur03AZTAIF+Ai4PnAqcBF+wJGkjQZ0zgMtR7Y0qa3AOcM1a+qgRuB5UmOA84EtlXV7qraA2wD1k24Z0la0sYdFgX8fZJbkmxqtWOr6r42/WXg2Da9Arh3aN0drTZfXZI0IcvGvP0fq6qdSZ4ObEvyr8MLq6qS1EJ8UAujTQAnnHDCQmxSktSMdc+iqna29/uBDzE45/CVdniJ9n5/G74TOH5o9ZWtNl99/8+6vKrWVNWamZmZhf5TJGlJG1tYJPnOJE/eNw2sBe4AtgL7rmjaAFzbprcC57Wrok4DHmyHq64D1iY5up3YXttqkqQJGedhqGOBDyXZ9zl/VVUfS3IzcE2SjcAXgZe28R8FzgZmgW8A5wNU1e4kbwJubuMurqrdY+xbkrSfsYVFVX0eePYc9QeAM+aoF3DBPNvaDGxe6B4lSaPxDm5JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpa+xhkeSoJJ9J8pE2f2KSm5LMJnlfkse1+uPb/GxbvmpoG29o9c8mOXPcPUuS/r9J7Fm8Frh7aP5twCVVdRKwB9jY6huBPa1+SRtHkpOBc4EfANYB70ly1AT6liQ1Yw2LJCuBnwL+rM0HeBHw/jZkC3BOm17f5mnLz2jj1wNXV9W3qurfgFng1HH2LUn6/8a9Z/HHwK8D/9PmnwZ8tar2tvkdwIo2vQK4F6Atf7CN/3Z9jnW+LcmmJNuTbN+1a9cC/xmStLSNLSyS/DRwf1XdMq7PGFZVl1fVmqpaMzMzM4mPlKQlY9kYt3068LNJzgaeAHwXcCmwPMmytvewEtjZxu8Ejgd2JFkGPAV4YKi+z/A6kqQJGNueRVW9oapWVtUqBieoP15VrwBuAF7chm0Arm3TW9s8bfnHq6pa/dx2tdSJwGrg0+PqW5L0SOPcs5jPbwBXJ3kz8Bngila/AnhvkllgN4OAoaruTHINcBewF7igqh6efNuStHRNJCyq6h+Af2jTn2eOq5mq6pvAS+ZZ/y3AW8bXoSTpQLyDW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV3TeES5tGC+dPEPTruFI94Jv3P7tFvQIuCehSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXSGGR5PpRapKkI9MB77NI8gTgicAxSY4G0hZ9F7BizL1JkhaJ3k15vwy8Dvge4Bb+LyweAt41vrYkSYvJAcOiqi4FLk3yK1X1zgn1JElaZEZ63EdVvTPJjwKrhtepqqvG1JckaREZKSySvBd4JnAr8HArF2BYSNISMOqDBNcAJ1dVjbMZSdLiNOp9FncA330wG07yhCSfTvIvSe5M8sZWPzHJTUlmk7wvyeNa/fFtfrYtXzW0rTe0+meTnHkwfUiSDt2oYXEMcFeS65Js3ffqrPMt4EVV9WzgFGBdktOAtwGXVNVJwB5gYxu/EdjT6pe0cSQ5GTgX+AFgHfCeJEeN/BdKkg7ZqIehfvdgN9wOWX29zT62vQp4EfDyVt/Stn0ZsH7oc94PvCtJWv3qqvoW8G9JZoFTgU8dbE+SpEdn1Kuh/vHRbLztAdwCnAS8G/gc8NWq2tuG7OD/bu5bAdzbPm9vkgeBp7X6jUObHV5n+LM2AZsATjjhhEfTriRpHqM+7uNrSR5qr28meTjJQ731qurhqjoFWMlgb+D7Dq3dA37W5VW1pqrWzMzMjOtjJGlJGnXP4sn7pocODZ026odU1VeT3AD8CLA8ybK2d7ES2NmG7QSOB3YkWQY8BXhgqL7P8DqSpAk46KfO1sCHgQNelZRkJsnyNv0dwE8CdwM3AC9uwzYA17bprW2etvzj7bzHVuDcdrXUicBq4NMH27ck6dEb9aa8nxuafQyD+y6+2VntOGBLO2/xGOCaqvpIkruAq5O8GfgMcEUbfwXw3nYCezeDK6CoqjuTXAPcBewFLqiqh5EkTcyoV0P9zND0XuALDA5FzauqbgOeM0f98wzOX+xf/ybwknm29RbgLSP2KklaYKOeszh/3I1IkhavUa+GWpnkQ0nub68PJFk57uYkSYvDqCe4/5zBiebvaa+/bTVJ0hIwaljMVNWfV9Xe9roS8GYGSVoiRg2LB5K8MslR7fVKBvdASJKWgFHD4tXAS4EvA/cxuA/iF8bUkyRpkRn10tmLgQ1VtQcgyVOBP2QQIpKkI9yoYfFD+4ICoKp2J3nEPRSSdDBOf+fp027hiPfJX/nkgmxn1MNQj0ly9L6ZtmcxatBIkg5zo/4H/4+ATyX5mzb/EryjWpKWjFHv4L4qyXYGP1wE8HNVddf42pIkLSYjH0pq4WBASNISdNCPKJckLT2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoaW1gkOT7JDUnuSnJnkte2+lOTbEtyT3s/utWT5B1JZpPcluS5Q9va0Mbfk2TDuHqWJM1tnHsWe4Ffq6qTgdOAC5KcDFwIXF9Vq4Hr2zzAWcDq9toEXAaDcAEuAp4PnApctC9gJEmTMbawqKr7quqf2/TXgLuBFcB6YEsbtgU4p02vB66qgRuB5UmOA84EtlXV7qraA2wD1o2rb0nSI03knEWSVcBzgJuAY6vqvrboy8CxbXoFcO/Qajtabb76/p+xKcn2JNt37dq1sH+AJC1xYw+LJE8CPgC8rqoeGl5WVQXUQnxOVV1eVWuqas3MzMxCbFKS1Iw1LJI8lkFQ/GVVfbCVv9IOL9He72/1ncDxQ6uvbLX56pKkCRnn1VABrgDurqq3Dy3aCuy7omkDcO1Q/bx2VdRpwIPtcNV1wNokR7cT22tbTZI0IcvGuO3TgVcBtye5tdV+E3grcE2SjcAXgZe2ZR8FzgZmgW8A5wNU1e4kbwJubuMurqrdY+xbkrSfsYVFVf0TkHkWnzHH+AIumGdbm4HNC9edJOlgeAe3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSusYVFks1J7k9yx1DtqUm2JbmnvR/d6knyjiSzSW5L8tyhdTa08fck2TCufiVJ8xvnnsWVwLr9ahcC11fVauD6Ng9wFrC6vTYBl8EgXICLgOcDpwIX7QsYSdLkjC0squoTwO79yuuBLW16C3DOUP2qGrgRWJ7kOOBMYFtV7a6qPcA2HhlAkqQxm/Q5i2Or6r42/WXg2Da9Arh3aNyOVpuv/ghJNiXZnmT7rl27FrZrSVripnaCu6oKqAXc3uVVtaaq1szMzCzUZiVJTD4svtIOL9He72/1ncDxQ+NWttp8dUnSBE06LLYC+65o2gBcO1Q/r10VdRrwYDtcdR2wNsnR7cT22laTJE3QsnFtOMlfAy8Ejkmyg8FVTW8FrkmyEfgi8NI2/KPA2cAs8A3gfICq2p3kTcDNbdzFVbX/SXNJ0piNLSyq6mXzLDpjjrEFXDDPdjYDmxewNUnSQfIObklSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnrsAmLJOuSfDbJbJILp92PJC0lh0VYJDkKeDdwFnAy8LIkJ0+3K0laOg6LsABOBWar6vNV9V/A1cD6KfckSUtGqmraPXQleTGwrqp+sc2/Cnh+Vb1maMwmYFOb/V7gsxNvdHKOAf592k3oUfP7O3wd6d/dM6pqZq4FyybdybhU1eXA5dPuYxKSbK+qNdPuQ4+O39/hayl/d4fLYaidwPFD8ytbTZI0AYdLWNwMrE5yYpLHAecCW6fckyQtGYfFYaiq2pvkNcB1wFHA5qq6c8ptTdOSONx2BPP7O3wt2e/usDjBLUmarsPlMJQkaYoMC0lSl2GxiPUecZLk8Une15bflGTVFNrUHJJsTnJ/kjvmWZ4k72jf3W1JnjvpHjW3JMcnuSHJXUnuTPLaOcYsue/PsFikRnzEyUZgT1WdBFwCvG2yXeoArgTWHWD5WcDq9toEXDaBnjSavcCvVdXJwGnABXP8u7fkvj/DYvEa5REn64Etbfr9wBlJMsEeNY+q+gSw+wBD1gNX1cCNwPIkx02mOx1IVd1XVf/cpr8G3A2s2G/Ykvv+DIvFawVw79D8Dh75D+y3x1TVXuBB4GkT6U6HapTvV1PWDu0+B7hpv0VL7vszLCRpDkmeBHwAeF1VPTTtfqbNsFi8RnnEybfHJFkGPAV4YCLd6VD5CJtFLMljGQTFX1bVB+cYsuS+P8Ni8RrlESdbgQ1t+sXAx8u7LA8XW4Hz2lU1pwEPVtV9025KgyudgCuAu6vq7fMMW3Lf32HxuI+laL5HnCS5GNheVVsZ/AP93iSzDE6mnju9jjUsyV8DLwSOSbIDuAh4LEBV/QnwUeBsYBb4BnD+dDrVHE4HXgXcnuTWVvtN4ARYut+fj/uQJHV5GEqS1GVYSJK6DAtJUpdhIUnqMiwkSV1eOiuNKMnTgOvb7HcDDwO72vyp7RleC/VZy4GXV9V7Fmqb0qHw0lnpUUjyu8DXq+oPRxi7rD2762C2vwr4SFU969F1KC0sD0NJhyDJLyW5Ocm/JPlAkie2+pVJ/iTJTcDvJ3lmkhuT3J7kzUm+PrSN17dt3Jbkja38VuCZSW5N8gdJjkvyiTZ/R5Ifn8KfqyXMsJAOzQer6oer6tkMHmW9cWjZSuBHq+pXgUuBS6vqBxk8oRSAJGsZ/CbCqcApwPOSvAC4EPhcVZ1SVa8HXg5cV1WnAM8Gbh33HyYN85yFdGieleTNwHLgSQwez7LP31TVw236R4Bz2vRfAfsOX61tr8+0+ScxCI8v7fc5NwOb2wPuPlxVty7cnyD1uWchHZorgde0PYY3Ak8YWvYfI6wf4PfaHsQpVXVSVV2x/6D2Y0ovYPBk0yuTnHforUujMyykQ/Nk4L72f/yvOMC4G4Gfb9PDD3y8Dnh1++0EkqxI8nTga23btPozgK9U1Z8CfwYc8b/5rMXFw1DSofltBr+itqu9P3meca8D/iLJbwEfY/CrhlTV3yf5fuBT7Rdxvw68sqo+l+STSe4A/g64A3h9kv9uY9yz0ER56aw0Ae0qqf+sqkpyLvCyqtr/N9WlRcs9C2kynge8q/2wzleBV0+3HenguGchSeryBLckqcuwkCR1GRaSpC7DQpLUZVhIkrr+FyC772r2VD94AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_df = preprocess_seq_data(chart_df) \n",
    "\n",
    "sns.countplot(chart_df, x=\"Targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb49369-2feb-4a50-a577-d848b6f0c218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9449, 68), (9449,), (1181, 68), (1181,), (1182, 68), (1182,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = []\n",
    "for col in chart_df.columns:\n",
    "    if col not in [\"Targets\", \"datetime\", \"years\"]:\n",
    "        train_columns.append(col)  \n",
    "\n",
    "X = chart_df[train_columns] \n",
    "Y = chart_df[\"Targets\"] \n",
    "\n",
    "train_size = int(chart_df.shape[0] * 0.8) \n",
    "val_size = int(chart_df.shape[0] * 0.1) \n",
    "\n",
    "X_train = X.iloc[:train_size] \n",
    "Y_train = Y.iloc[:train_size] \n",
    "\n",
    "X_val = X.iloc[train_size:train_size+val_size] \n",
    "Y_val = Y.iloc[train_size:train_size+val_size] \n",
    "\n",
    "X_test = X.iloc[train_size+val_size:] \n",
    "Y_test = Y.iloc[train_size+val_size:] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a8c5a7-d951-46d9-b72f-c187fd290584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2363, 69)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.concat([X_val, Y_val], axis=1) \n",
    "test = pd.concat([X_test, Y_test], axis=1) \n",
    "\n",
    "full_df = pd.concat([val, test], axis=0) \n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c337011c-8c7f-410a-b8e5-5b502a16234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xgb_chart_similar_dates_DTW.pkl\", \"rb\") as f: \n",
    "    similar_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df78eb3-d893-41f7-acc6-4a0b23d48c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ec77bdde6543dc8ca1ffceae43c716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comp_columns = train_columns[3:] \n",
    "\n",
    "date_chart_info = {} # date, index \n",
    "\n",
    "all_dates = chart_df.index \n",
    "\n",
    "for i in tqdm(range(len(all_dates)), position=0, leave=True): \n",
    "    date_chart_info[all_dates[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091effd8-bbb5-41ee-a491-9f2bfff24f93",
   "metadata": {},
   "source": [
    "# No Similar Patterns Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a977640b-8879-4f04-90c4-ad7e259349c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 69), (236, 69), (237, 69))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * full_df.shape[0]) \n",
    "val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "train_df = full_df.iloc[:train_size] \n",
    "val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "test_df = full_df.iloc[train_size+val_size:] \n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e23c29-6be9-4b9d-953b-58cf103c5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [] \n",
    "for col in train_df.columns: \n",
    "    if col not in [\"Targets\"]: \n",
    "        train_columns.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bceb7bb-69f8-4c48-a0e9-91d49a18704b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 68), (1890,), (236, 68), (236,), (237, 68), (237,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df[train_columns] \n",
    "Y_train = train_df[\"Targets\"] \n",
    "\n",
    "X_val = val_df[train_columns] \n",
    "Y_val = val_df[\"Targets\"] \n",
    "\n",
    "X_test = test_df[train_columns] \n",
    "Y_test = test_df[\"Targets\"] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054d08ea-f6cc-4ba5-8d8f-101eef2843ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:35:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:35:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07640\n",
      "[20]\tvalidation_0-mlogloss:1.06534\n",
      "[40]\tvalidation_0-mlogloss:1.15647\n",
      "[60]\tvalidation_0-mlogloss:1.19999\n",
      "[80]\tvalidation_0-mlogloss:1.25483\n",
      "[100]\tvalidation_0-mlogloss:1.28639\n",
      "[120]\tvalidation_0-mlogloss:1.31688\n",
      "[140]\tvalidation_0-mlogloss:1.33819\n",
      "[160]\tvalidation_0-mlogloss:1.36550\n",
      "[180]\tvalidation_0-mlogloss:1.39386\n",
      "[199]\tvalidation_0-mlogloss:1.40875\n",
      "accuracy : 51.89873417721519% | Weighted F1 : 0.5803859518490941\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(silent=False, \n",
    "                    n_estimators=200,\n",
    "                    class_weight=d, \n",
    "                    metric=\"logloss\",\n",
    "                    tree_method=\"gpu_hist\")\n",
    "\n",
    "clf.fit(X_train, \n",
    "        Y_train, \n",
    "        eval_set=[(X_val, Y_val)],\n",
    "        verbose=20)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "cnt = 0 \n",
    "for i in range(len(Y_pred)): \n",
    "    if Y_pred[i] == Y_test[i]: \n",
    "        cnt += 1 \n",
    "        \n",
    "accuracy = cnt / len(Y_pred) * 100\n",
    "f1 = f1_score(Y_test, Y_pred, average=\"weighted\") \n",
    "\n",
    "print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c754c9-c941-4256-b746-be33c81c85d8",
   "metadata": {},
   "source": [
    "# With similar patterns used: scores softmax normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28f9d021-29e9-445d-bb5c-a9e92afafe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d8feebcb44f2f90c4124bd09eae73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[15:36:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:36:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07872\n",
      "[20]\tvalidation_0-mlogloss:1.06550\n",
      "[40]\tvalidation_0-mlogloss:1.13500\n",
      "[60]\tvalidation_0-mlogloss:1.19829\n",
      "[80]\tvalidation_0-mlogloss:1.24747\n",
      "[100]\tvalidation_0-mlogloss:1.27955\n",
      "[120]\tvalidation_0-mlogloss:1.31704\n",
      "[140]\tvalidation_0-mlogloss:1.35126\n",
      "[160]\tvalidation_0-mlogloss:1.38016\n",
      "[180]\tvalidation_0-mlogloss:1.38895\n",
      "[199]\tvalidation_0-mlogloss:1.40954\n",
      "Top 5 similar patterns used\n",
      "accuracy : 53.58649789029536% | Weighted F1 : 0.5959191609816683\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f20b458b63d487d97dc5cd0dac1f5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[15:36:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:36:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08397\n",
      "[20]\tvalidation_0-mlogloss:1.12035\n",
      "[40]\tvalidation_0-mlogloss:1.16258\n",
      "[60]\tvalidation_0-mlogloss:1.22714\n",
      "[80]\tvalidation_0-mlogloss:1.27078\n",
      "[100]\tvalidation_0-mlogloss:1.30976\n",
      "[120]\tvalidation_0-mlogloss:1.34262\n",
      "[140]\tvalidation_0-mlogloss:1.38476\n",
      "[160]\tvalidation_0-mlogloss:1.39935\n",
      "[180]\tvalidation_0-mlogloss:1.42949\n",
      "[199]\tvalidation_0-mlogloss:1.45488\n",
      "Top 10 similar patterns used\n",
      "accuracy : 52.320675105485236% | Weighted F1 : 0.5803858387776372\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160189a39c214c81bcb32e09a62271e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[15:36:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:36:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08929\n",
      "[20]\tvalidation_0-mlogloss:1.11138\n",
      "[40]\tvalidation_0-mlogloss:1.17251\n",
      "[60]\tvalidation_0-mlogloss:1.24947\n",
      "[80]\tvalidation_0-mlogloss:1.30434\n",
      "[100]\tvalidation_0-mlogloss:1.35797\n",
      "[120]\tvalidation_0-mlogloss:1.39513\n",
      "[140]\tvalidation_0-mlogloss:1.44136\n",
      "[160]\tvalidation_0-mlogloss:1.46379\n",
      "[180]\tvalidation_0-mlogloss:1.48306\n",
      "[199]\tvalidation_0-mlogloss:1.49873\n",
      "Top 15 similar patterns used\n",
      "accuracy : 53.16455696202531% | Weighted F1 : 0.5919977223949893\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34ac5a9b41e4119962471b1a488fa0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[15:36:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:36:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08875\n",
      "[20]\tvalidation_0-mlogloss:1.10870\n",
      "[40]\tvalidation_0-mlogloss:1.15315\n",
      "[60]\tvalidation_0-mlogloss:1.19757\n",
      "[80]\tvalidation_0-mlogloss:1.25045\n",
      "[100]\tvalidation_0-mlogloss:1.30028\n",
      "[120]\tvalidation_0-mlogloss:1.34757\n",
      "[140]\tvalidation_0-mlogloss:1.36917\n",
      "[160]\tvalidation_0-mlogloss:1.38630\n",
      "[180]\tvalidation_0-mlogloss:1.41025\n",
      "[199]\tvalidation_0-mlogloss:1.42740\n",
      "Top 20 similar patterns used\n",
      "accuracy : 52.742616033755276% | Weighted F1 : 0.5889400141034821\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c299b4f0d3b44299b3a39576f096c63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[15:36:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:36:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08006\n",
      "[20]\tvalidation_0-mlogloss:1.07786\n",
      "[40]\tvalidation_0-mlogloss:1.10821\n",
      "[60]\tvalidation_0-mlogloss:1.15104\n",
      "[80]\tvalidation_0-mlogloss:1.19838\n",
      "[100]\tvalidation_0-mlogloss:1.24953\n",
      "[120]\tvalidation_0-mlogloss:1.28084\n",
      "[140]\tvalidation_0-mlogloss:1.31027\n",
      "[160]\tvalidation_0-mlogloss:1.34276\n",
      "[180]\tvalidation_0-mlogloss:1.37319\n",
      "[199]\tvalidation_0-mlogloss:1.40114\n",
      "Top 25 similar patterns used\n",
      "accuracy : 53.58649789029536% | Weighted F1 : 0.5948350972311176\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69af9c51cd454f6b869c26edcd58aeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[15:36:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:36:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.08723\n",
      "[20]\tvalidation_0-mlogloss:1.09232\n",
      "[40]\tvalidation_0-mlogloss:1.12749\n",
      "[60]\tvalidation_0-mlogloss:1.18993\n",
      "[80]\tvalidation_0-mlogloss:1.24593\n",
      "[100]\tvalidation_0-mlogloss:1.28411\n",
      "[120]\tvalidation_0-mlogloss:1.32259\n",
      "[140]\tvalidation_0-mlogloss:1.35923\n",
      "[160]\tvalidation_0-mlogloss:1.38875\n",
      "[180]\tvalidation_0-mlogloss:1.40996\n",
      "[199]\tvalidation_0-mlogloss:1.43538\n",
      "Top 30 similar patterns used\n",
      "accuracy : 55.27426160337553% | Weighted F1 : 0.6042755579776561\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "accuracies, f1_scores = [], [] \n",
    "\n",
    "for topk in [5, 10, 15, 20, 25, 30]: \n",
    "    long_cnt, short_cnt, hold_cnt = [], [], [] \n",
    "    vote_accuracy = 0 \n",
    "    for key, value in tqdm(similar_dict.items(), position=0, leave=True): \n",
    "        query_idx = date_chart_info[key] \n",
    "        query_target = chart_df[\"Targets\"].iloc[query_idx] \n",
    "        cnt_map = {0:0, 1:0, 2:0} \n",
    "        for i in range(len(value[:topk])): \n",
    "            candidate_idx = date_chart_info[value[i][0]] \n",
    "            candidate_target = chart_df[\"Targets\"].iloc[candidate_idx] \n",
    "            cnt_map[candidate_target] += 1 \n",
    "        softmaxed = nn.Softmax()(torch.tensor([cnt_map[0], cnt_map[1], cnt_map[2]]).float()) \n",
    "        long_cnt.append(softmaxed[0].item()) \n",
    "        short_cnt.append(softmaxed[1].item()) \n",
    "        hold_cnt.append(softmaxed[2].item()) \n",
    "    \n",
    "    full_df[\"long_vote\"] = long_cnt \n",
    "    full_df[\"short_vote\"] = short_cnt \n",
    "    full_df[\"hold_vote\"] = hold_cnt \n",
    "        \n",
    "    train_size = int(0.8 * full_df.shape[0]) \n",
    "    val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "    train_df = full_df.iloc[:train_size] \n",
    "    val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "    test_df = full_df.iloc[train_size+val_size:]  \n",
    "    \n",
    "    train_columns = [] \n",
    "    for col in train_df.columns: \n",
    "        if col not in [\"Targets\"]: \n",
    "            train_columns.append(col) \n",
    "            \n",
    "    X_train = train_df[train_columns] \n",
    "    Y_train = train_df[\"Targets\"] \n",
    "\n",
    "    X_val = val_df[train_columns] \n",
    "    Y_val = val_df[\"Targets\"] \n",
    "\n",
    "    X_test = test_df[train_columns] \n",
    "    Y_test = test_df[\"Targets\"] \n",
    "    \n",
    "    print(\"printing dataframe shapes\") \n",
    "    print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "    \n",
    "    FE_clf = XGBClassifier(silent=False, \n",
    "                           n_estimators=200,\n",
    "                           class_weight=d, \n",
    "                           metric=\"logloss\",\n",
    "                           tree_method=\"gpu_hist\")  \n",
    "    FE_clf.fit(X_train, \n",
    "               Y_train, \n",
    "               eval_set=[(X_val, Y_val)],\n",
    "               verbose=20) \n",
    "    \n",
    "    \n",
    "    Y_pred = FE_clf.predict(X_test)\n",
    "\n",
    "    cnt = 0 \n",
    "    for i in range(len(Y_pred)): \n",
    "        if Y_pred[i] == Y_test[i]: \n",
    "            cnt += 1 \n",
    "\n",
    "    accuracy = cnt / len(Y_pred) * 100\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Top {topk} similar patterns used\") \n",
    "    print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") \n",
    "    print(\"=\"*50) \n",
    "    \n",
    "    accuracies.append(accuracy) \n",
    "    f1_scores.append(f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d9f508d-27d5-4d12-8fd7-cbd4a9848632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 53.445850914205344% | mean weighted F1: 0.5927255652444251\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies) \n",
    "mean_f1 = np.mean(f1_scores) \n",
    "\n",
    "print(f\"mean accuracy: {mean_accuracy}% | mean weighted F1: {mean_f1}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea3dfc-a3c6-4898-a475-8f5ee942ec55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
