{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51dfbbb-8f5a-4d1b-a90e-b361803f9a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import random \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65307ecf-9907-444d-9cad-8d31b4170b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b61ed2ce41a4344897ec964774da45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"BTC_USDT-4h-12.json\") as f: \n",
    "    d = json.load(f) \n",
    "\n",
    "chart_df = pd.DataFrame(d) \n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "    binance = ccxt.binance() \n",
    "    dates = df[\"timestamp\"].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)):\n",
    "        date_string = binance.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string) \n",
    "    df[\"datetime\"] = timestamp\n",
    "    df = df.drop(columns={\"timestamp\"}) \n",
    "    return df \n",
    "\n",
    "chart_df = process(chart_df) \n",
    "\n",
    "hours, days, months, years = [],[],[],[] \n",
    "for dt in tqdm(chart_df[\"datetime\"]):\n",
    "        dtobj = pd.to_datetime(dt) \n",
    "        hour = dtobj.hour \n",
    "        day = dtobj.day \n",
    "        month = dtobj.month \n",
    "        year = dtobj.year \n",
    "        hours.append(hour) \n",
    "        days.append(day) \n",
    "        months.append(month) \n",
    "        years.append(year) \n",
    "\n",
    "chart_df[\"hours\"] = hours \n",
    "chart_df[\"days\"] = days  \n",
    "chart_df[\"months\"] = months \n",
    "chart_df[\"years\"] = years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8f3786-78ea-4572-9df6-a93a6b782d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_data(chart_df, threshold=0.0075): \n",
    "    targets = [] \n",
    "    openv = chart_df[\"open\"].values \n",
    "    close = chart_df[\"close\"].values \n",
    "    high = chart_df[\"high\"].values \n",
    "    low = chart_df[\"low\"].values  \n",
    "    volume = chart_df[\"volume\"].values \n",
    "    \n",
    "    for i in range(close.shape[0]-1):\n",
    "        high_vol = (high[i+1] - close[i]) / close[i] \n",
    "        low_vol = (low[i+1] - close[i]) / close[i] \n",
    "        if high_vol >= threshold: \n",
    "            targets.append(0) \n",
    "        elif low_vol <= -threshold:\n",
    "            targets.append(1) \n",
    "        else:\n",
    "            targets.append(2) \n",
    "        \n",
    "    targets.append(None) \n",
    "    chart_df[\"Targets\"] = targets \n",
    "    \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True)\n",
    "    chart_df[\"bop\"] = chart_df.ta.bop(lookahead=False) \n",
    "    chart_df[\"ebsw\"] = chart_df.ta.ebsw(lookahead=False) \n",
    "    chart_df[\"cmf\"] = chart_df.ta.cmf(lookahead=False) \n",
    "    chart_df[\"rsi/100\"] = chart_df.ta.rsi(lookahead=False) / 100\n",
    "    chart_df[\"high/low\"] = chart_df[\"high\"] / chart_df[\"low\"] \n",
    "    chart_df[\"high/open\"] = chart_df[\"high\"] / chart_df[\"open\"] \n",
    "    chart_df[\"low/open\"] = chart_df[\"low\"] / chart_df[\"open\"] \n",
    "    chart_df[\"close/open\"] = chart_df[\"close\"] / chart_df[\"open\"] \n",
    "    chart_df[\"high/close\"] = chart_df[\"high\"] / chart_df[\"close\"] \n",
    "    chart_df[\"low/close\"] = chart_df[\"low\"] / chart_df[\"close\"]     \n",
    "    for l in tqdm(range(1, 12), position=0, leave=True): \n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "            val = chart_df[col].values \n",
    "            val_ret = [None for _ in range(l)]\n",
    "            for i in range(l, len(val)):\n",
    "                if val[i-l] == 0: \n",
    "                    ret = 1 \n",
    "                else:\n",
    "                    ret = val[i] / val[i-l]  \n",
    "                val_ret.append(ret) \n",
    "            chart_df[\"{}_change_{}\".format(col, l)] = val_ret \n",
    "\n",
    "    chart_df.dropna(inplace=True) \n",
    "    chart_df.drop(columns={\"open\", \"high\", \"low\", \"close\", \"volume\"}, inplace=True) \n",
    "    return chart_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc343e9-f96d-45e9-938c-e9779570083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0303229051d046be8ed67631373e0ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Targets', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_df = preprocess_seq_data(chart_df) \n",
    "\n",
    "sns.countplot(chart_df, x=\"Targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89c4c2a-5d58-43f5-aee6-174ca9a1a9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9449, 68), (9449,), (1181, 68), (1181,), (1182, 68), (1182,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = []\n",
    "for col in chart_df.columns:\n",
    "    if col not in [\"Targets\", \"datetime\", \"years\"]:\n",
    "        train_columns.append(col)  \n",
    "\n",
    "X = chart_df[train_columns] \n",
    "Y = chart_df[\"Targets\"] \n",
    "\n",
    "train_size = int(chart_df.shape[0] * 0.8) \n",
    "val_size = int(chart_df.shape[0] * 0.1) \n",
    "\n",
    "X_train = X.iloc[:train_size] \n",
    "Y_train = Y.iloc[:train_size] \n",
    "\n",
    "X_val = X.iloc[train_size:train_size+val_size] \n",
    "Y_val = Y.iloc[train_size:train_size+val_size] \n",
    "\n",
    "X_test = X.iloc[train_size+val_size:] \n",
    "Y_test = Y.iloc[train_size+val_size:] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa2ad36-2116-4525-b6d6-3459b2134fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2363, 69)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.concat([X_val, Y_val], axis=1) \n",
    "test = pd.concat([X_test, Y_test], axis=1) \n",
    "\n",
    "full_df = pd.concat([val, test], axis=0) \n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78af5961-3551-4b7e-8a79-5d99f68e3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ts2vec_similar_dates.pkl\", \"rb\") as f: \n",
    "    similar_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950902f8-8754-4940-afee-3ee2b91ff09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c8585c43f0460cb0d18dc1e3b8feac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comp_columns = train_columns[3:] \n",
    "\n",
    "date_chart_info = {} # date, index \n",
    "\n",
    "all_dates = chart_df.index \n",
    "\n",
    "for i in tqdm(range(len(all_dates)), position=0, leave=True): \n",
    "    date_chart_info[all_dates[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20477b8-484b-4c57-bd9f-5e33f8fbe4d9",
   "metadata": {},
   "source": [
    "# No Similar Patterns Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7157685-30f1-423a-96b4-5f3313175515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 69), (236, 69), (237, 69))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * full_df.shape[0]) \n",
    "val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "train_df = full_df.iloc[:train_size] \n",
    "val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "test_df = full_df.iloc[train_size+val_size:] \n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b3b16c-82e4-43c7-af81-5d7c82747901",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [] \n",
    "for col in train_df.columns: \n",
    "    if col not in [\"Targets\"]: \n",
    "        train_columns.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7a4a67-dde5-44c6-8488-08d023cf10bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1890, 68), (1890,), (236, 68), (236,), (237, 68), (237,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df[train_columns] \n",
    "Y_train = train_df[\"Targets\"] \n",
    "\n",
    "X_val = val_df[train_columns] \n",
    "Y_val = val_df[\"Targets\"] \n",
    "\n",
    "X_test = test_df[train_columns] \n",
    "Y_test = test_df[\"Targets\"] \n",
    "\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3d66f8-c186-4177-bf8f-bb56357f16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:18:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07640\n",
      "[20]\tvalidation_0-mlogloss:1.06534\n",
      "[40]\tvalidation_0-mlogloss:1.15647\n",
      "[60]\tvalidation_0-mlogloss:1.19999\n",
      "[80]\tvalidation_0-mlogloss:1.25483\n",
      "[100]\tvalidation_0-mlogloss:1.28639\n",
      "[120]\tvalidation_0-mlogloss:1.31688\n",
      "[140]\tvalidation_0-mlogloss:1.33819\n",
      "[160]\tvalidation_0-mlogloss:1.36550\n",
      "[180]\tvalidation_0-mlogloss:1.39386\n",
      "[199]\tvalidation_0-mlogloss:1.40875\n",
      "accuracy : 51.89873417721519% | Weighted F1 : 0.5803859518490941\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(silent=False, \n",
    "                    n_estimators=200,\n",
    "                    class_weight=d, \n",
    "                    metric=\"logloss\",\n",
    "                    tree_method=\"gpu_hist\")\n",
    "\n",
    "clf.fit(X_train, \n",
    "        Y_train, \n",
    "        eval_set=[(X_val, Y_val)],\n",
    "        verbose=20)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "cnt = 0 \n",
    "for i in range(len(Y_pred)): \n",
    "    if Y_pred[i] == Y_test[i]: \n",
    "        cnt += 1 \n",
    "        \n",
    "accuracy = cnt / len(Y_pred) * 100\n",
    "f1 = f1_score(Y_test, Y_pred, average=\"weighted\") \n",
    "\n",
    "print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b27ba3-376c-4560-baa0-d9a9d096a874",
   "metadata": {},
   "source": [
    "# With similar patterns used: scores softmax normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68eb72b4-53ed-4315-bd59-780a9092c10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154c45835a21443e9564f22097567f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[09:18:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07698\n",
      "[20]\tvalidation_0-mlogloss:1.02140\n",
      "[40]\tvalidation_0-mlogloss:1.06222\n",
      "[60]\tvalidation_0-mlogloss:1.14723\n",
      "[80]\tvalidation_0-mlogloss:1.17261\n",
      "[100]\tvalidation_0-mlogloss:1.20981\n",
      "[120]\tvalidation_0-mlogloss:1.25945\n",
      "[140]\tvalidation_0-mlogloss:1.28266\n",
      "[160]\tvalidation_0-mlogloss:1.31129\n",
      "[180]\tvalidation_0-mlogloss:1.33164\n",
      "[199]\tvalidation_0-mlogloss:1.34533\n",
      "Top 5 similar patterns used\n",
      "accuracy : 56.540084388185655% | Weighted F1 : 0.6163799766426457\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aee37e32c3481bbb79141a5cdab338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[09:18:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07923\n",
      "[20]\tvalidation_0-mlogloss:1.06173\n",
      "[40]\tvalidation_0-mlogloss:1.10414\n",
      "[60]\tvalidation_0-mlogloss:1.16327\n",
      "[80]\tvalidation_0-mlogloss:1.20806\n",
      "[100]\tvalidation_0-mlogloss:1.24878\n",
      "[120]\tvalidation_0-mlogloss:1.27316\n",
      "[140]\tvalidation_0-mlogloss:1.30052\n",
      "[160]\tvalidation_0-mlogloss:1.32641\n",
      "[180]\tvalidation_0-mlogloss:1.35027\n",
      "[199]\tvalidation_0-mlogloss:1.37195\n",
      "Top 10 similar patterns used\n",
      "accuracy : 58.64978902953587% | Weighted F1 : 0.6348154584910538\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7556f2a310644e3cbca9aabdcbfefb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[09:18:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07831\n",
      "[20]\tvalidation_0-mlogloss:1.06267\n",
      "[40]\tvalidation_0-mlogloss:1.12465\n",
      "[60]\tvalidation_0-mlogloss:1.18870\n",
      "[80]\tvalidation_0-mlogloss:1.24750\n",
      "[100]\tvalidation_0-mlogloss:1.28143\n",
      "[120]\tvalidation_0-mlogloss:1.31321\n",
      "[140]\tvalidation_0-mlogloss:1.32529\n",
      "[160]\tvalidation_0-mlogloss:1.34858\n",
      "[180]\tvalidation_0-mlogloss:1.36892\n",
      "[199]\tvalidation_0-mlogloss:1.38148\n",
      "Top 15 similar patterns used\n",
      "accuracy : 50.210970464135016% | Weighted F1 : 0.5628247143610083\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c89e6c5ac4147078b3cbc4d95359773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[09:18:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07517\n",
      "[20]\tvalidation_0-mlogloss:1.07976\n",
      "[40]\tvalidation_0-mlogloss:1.11735\n",
      "[60]\tvalidation_0-mlogloss:1.15031\n",
      "[80]\tvalidation_0-mlogloss:1.21340\n",
      "[100]\tvalidation_0-mlogloss:1.26680\n",
      "[120]\tvalidation_0-mlogloss:1.29083\n",
      "[140]\tvalidation_0-mlogloss:1.33739\n",
      "[160]\tvalidation_0-mlogloss:1.36159\n",
      "[180]\tvalidation_0-mlogloss:1.38370\n",
      "[199]\tvalidation_0-mlogloss:1.39166\n",
      "Top 20 similar patterns used\n",
      "accuracy : 53.58649789029536% | Weighted F1 : 0.5927970802841022\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c1b4b1a9414a4f8774aa7c038df3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[09:18:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07693\n",
      "[20]\tvalidation_0-mlogloss:1.06861\n",
      "[40]\tvalidation_0-mlogloss:1.14111\n",
      "[60]\tvalidation_0-mlogloss:1.19495\n",
      "[80]\tvalidation_0-mlogloss:1.23449\n",
      "[100]\tvalidation_0-mlogloss:1.28782\n",
      "[120]\tvalidation_0-mlogloss:1.32542\n",
      "[140]\tvalidation_0-mlogloss:1.35422\n",
      "[160]\tvalidation_0-mlogloss:1.37213\n",
      "[180]\tvalidation_0-mlogloss:1.39175\n",
      "[199]\tvalidation_0-mlogloss:1.41159\n",
      "Top 25 similar patterns used\n",
      "accuracy : 51.89873417721519% | Weighted F1 : 0.5798384567910783\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed910e2188f4b19a3e406ca5f1c9484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe shapes\n",
      "(1890, 71) (1890,) (236, 71) (236,) (237, 71) (237,)\n",
      "[09:18:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"class_weight\", \"metric\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:18:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.07703\n",
      "[20]\tvalidation_0-mlogloss:1.05284\n",
      "[40]\tvalidation_0-mlogloss:1.09760\n",
      "[60]\tvalidation_0-mlogloss:1.14480\n",
      "[80]\tvalidation_0-mlogloss:1.19137\n",
      "[100]\tvalidation_0-mlogloss:1.23803\n",
      "[120]\tvalidation_0-mlogloss:1.27590\n",
      "[140]\tvalidation_0-mlogloss:1.30752\n",
      "[160]\tvalidation_0-mlogloss:1.32756\n",
      "[180]\tvalidation_0-mlogloss:1.34659\n",
      "[199]\tvalidation_0-mlogloss:1.36549\n",
      "Top 30 similar patterns used\n",
      "accuracy : 52.742616033755276% | Weighted F1 : 0.581586444693182\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "accuracies, f1_scores = [], [] \n",
    "\n",
    "for topk in [5, 10, 15, 20, 25, 30]: \n",
    "    long_cnt, short_cnt, hold_cnt = [], [], [] \n",
    "    vote_accuracy = 0 \n",
    "    for key, value in tqdm(similar_dict.items(), position=0, leave=True): \n",
    "        query_idx = date_chart_info[key] \n",
    "        query_target = chart_df[\"Targets\"].iloc[query_idx] \n",
    "        cnt_map = {0:0, 1:0, 2:0} \n",
    "        for i in range(len(value[:topk])): \n",
    "            candidate_idx = date_chart_info[value[i][0]] \n",
    "            candidate_target = chart_df[\"Targets\"].iloc[candidate_idx] \n",
    "            cnt_map[candidate_target] += 1 \n",
    "        softmaxed = nn.Softmax()(torch.tensor([cnt_map[0], cnt_map[1], cnt_map[2]]).float()) \n",
    "        long_cnt.append(softmaxed[0].item()) \n",
    "        short_cnt.append(softmaxed[1].item()) \n",
    "        hold_cnt.append(softmaxed[2].item()) \n",
    "    \n",
    "    full_df[\"long_vote\"] = long_cnt \n",
    "    full_df[\"short_vote\"] = short_cnt \n",
    "    full_df[\"hold_vote\"] = hold_cnt \n",
    "        \n",
    "    train_size = int(0.8 * full_df.shape[0]) \n",
    "    val_size = int(0.1 * full_df.shape[0]) \n",
    "\n",
    "    train_df = full_df.iloc[:train_size] \n",
    "    val_df = full_df.iloc[train_size:train_size+val_size] \n",
    "    test_df = full_df.iloc[train_size+val_size:]  \n",
    "    \n",
    "    train_columns = [] \n",
    "    for col in train_df.columns: \n",
    "        if col not in [\"Targets\"]: \n",
    "            train_columns.append(col) \n",
    "            \n",
    "    X_train = train_df[train_columns] \n",
    "    Y_train = train_df[\"Targets\"] \n",
    "\n",
    "    X_val = val_df[train_columns] \n",
    "    Y_val = val_df[\"Targets\"] \n",
    "\n",
    "    X_test = test_df[train_columns] \n",
    "    Y_test = test_df[\"Targets\"] \n",
    "    \n",
    "    print(\"printing dataframe shapes\") \n",
    "    print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)\n",
    "    \n",
    "    FE_clf = XGBClassifier(silent=False, \n",
    "                           n_estimators=200,\n",
    "                           class_weight=d, \n",
    "                           metric=\"logloss\",\n",
    "                           tree_method=\"gpu_hist\")  \n",
    "    FE_clf.fit(X_train, \n",
    "               Y_train, \n",
    "               eval_set=[(X_val, Y_val)],\n",
    "               verbose=20) \n",
    "    \n",
    "    \n",
    "    Y_pred = FE_clf.predict(X_test)\n",
    "\n",
    "    cnt = 0 \n",
    "    for i in range(len(Y_pred)): \n",
    "        if Y_pred[i] == Y_test[i]: \n",
    "            cnt += 1 \n",
    "\n",
    "    accuracy = cnt / len(Y_pred) * 100\n",
    "    f1 = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Top {topk} similar patterns used\") \n",
    "    print(f\"accuracy : {accuracy}% | Weighted F1 : {f1}\") \n",
    "    print(\"=\"*50) \n",
    "    \n",
    "    accuracies.append(accuracy) \n",
    "    f1_scores.append(f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f82507-cad6-4033-8b08-912be8f74207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 53.93811533052039% | mean weighted F1: 0.5947070218771784\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies) \n",
    "mean_f1 = np.mean(f1_scores) \n",
    "\n",
    "print(f\"mean accuracy: {mean_accuracy}% | mean weighted F1: {mean_f1}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a8ce1-dcd6-4cdf-9ac3-f1d4fe0ba63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726f1ae-e3f9-4b44-9a50-6484e1f2f5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4eb48-6835-4240-a852-456a824af8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778f2a3-f582-4a64-9e80-27ce2c0ef680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
