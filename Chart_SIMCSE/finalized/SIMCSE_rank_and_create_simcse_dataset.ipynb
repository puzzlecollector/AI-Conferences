{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427bfd9c-6ef3-46b0-9377-64ade7d41638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json \n",
    "import ccxt \n",
    "import seaborn as sns\n",
    "import os \n",
    "import pandas_ta as ta \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import * \n",
    "import torch \n",
    "from torch import Tensor \n",
    "from torch.utils.data import * \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from scipy.spatial.distance import cdist \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8ed1c-63f9-41c8-8f0e-6d9f2215aad7",
   "metadata": {},
   "source": [
    "### Load Trained BTC Chart SimCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167a14b0-a830-4748-a72a-6f0eb02f258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode =  full\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load 300 epoch trained SimCSE \n",
    "### define model ### \n",
    "class DAIN_Layer(nn.Module):\n",
    "    def __init__(self, mode, mean_lr, gate_lr, scale_lr, input_dim):\n",
    "        super(DAIN_Layer, self).__init__()\n",
    "        print(\"Mode = \", mode)\n",
    "        self.mode = mode\n",
    "        self.mean_lr = mean_lr\n",
    "        self.gate_lr = gate_lr\n",
    "        self.scale_lr = scale_lr\n",
    "        # Parameters for adaptive average\n",
    "        self.mean_layer = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.mean_layer.weight.data = torch.FloatTensor(data=np.eye(input_dim, input_dim))\n",
    "        # Parameters for adaptive std\n",
    "        self.scaling_layer = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.scaling_layer.weight.data = torch.FloatTensor(data=np.eye(input_dim, input_dim))\n",
    "        # Parameters for adaptive scaling\n",
    "        self.gating_layer = nn.Linear(input_dim, input_dim)\n",
    "        self.eps = 1e-8\n",
    "    def forward(self, x):\n",
    "        # Expecting  (n_samples, dim,  n_feature_vectors)\n",
    "        # Nothing to normalize\n",
    "        if self.mode == None:\n",
    "            pass\n",
    "        # Do simple average normalization\n",
    "        elif self.mode == 'avg':\n",
    "            avg = torch.mean(x, 2)\n",
    "            avg = avg.resize(avg.size(0), avg.size(1), 1)\n",
    "            x = x - avg\n",
    "        # Perform only the first step (adaptive averaging)\n",
    "        elif self.mode == 'adaptive_avg':\n",
    "            avg = torch.mean(x, 2)\n",
    "            adaptive_avg = self.mean_layer(avg)\n",
    "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
    "            x = x - adaptive_avg\n",
    "        # Perform the first + second step (adaptive averaging + adaptive scaling )\n",
    "        elif self.mode == 'adaptive_scale':\n",
    "            # Step 1:\n",
    "            avg = torch.mean(x, 2)\n",
    "            adaptive_avg = self.mean_layer(avg)\n",
    "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
    "            x = x - adaptive_avg\n",
    "            # Step 2:\n",
    "            std = torch.mean(x ** 2, 2)\n",
    "            std = torch.sqrt(std + self.eps)\n",
    "            adaptive_std = self.scaling_layer(std)\n",
    "            adaptive_std[adaptive_std <= self.eps] = 1\n",
    "            adaptive_std = adaptive_std.resize(adaptive_std.size(0), adaptive_std.size(1), 1)\n",
    "            x = x / (adaptive_std)\n",
    "        elif self.mode == 'full':\n",
    "            # Step 1:\n",
    "            avg = torch.mean(x, 2)\n",
    "            adaptive_avg = self.mean_layer(avg)\n",
    "            adaptive_avg = adaptive_avg.resize(adaptive_avg.size(0), adaptive_avg.size(1), 1)\n",
    "            x = x - adaptive_avg\n",
    "            # # Step 2:\n",
    "            std = torch.mean(x ** 2, 2)\n",
    "            std = torch.sqrt(std + self.eps)\n",
    "            adaptive_std = self.scaling_layer(std)\n",
    "            adaptive_std[adaptive_std <= self.eps] = 1\n",
    "            adaptive_std = adaptive_std.resize(adaptive_std.size(0), adaptive_std.size(1), 1)\n",
    "            x = x / adaptive_std\n",
    "            # Step 3: \n",
    "            avg = torch.mean(x, 2)\n",
    "            gate = F.sigmoid(self.gating_layer(avg))\n",
    "            gate = gate.resize(gate.size(0), gate.size(1), 1)\n",
    "            x = x * gate\n",
    "        else:\n",
    "            assert False\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "        def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "                super(PositionalEncoding, self).__init__() \n",
    "                self.dropout = nn.Dropout(p=dropout) \n",
    "                pe = torch.zeros(max_len, d_model) \n",
    "                position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) \n",
    "                div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) \n",
    "                pe[:, 0::2] = torch.sin(position * div_term) \n",
    "                pe[:, 1::2] = torch.cos(position * div_term) \n",
    "                pe = pe.unsqueeze(0).transpose(0, 1) \n",
    "                self.register_buffer(\"pe\", pe) \n",
    "        def forward(self, x):\n",
    "                x = x + self.pe[:x.size(0), :] \n",
    "                return self.dropout(x) \n",
    "\n",
    "# returns chart embedding \n",
    "class BTCSimCSE(nn.Module): \n",
    "        def __init__(self, chart_features, sequence_length, d_model, n_heads, num_encoders):\n",
    "                super(BTCSimCSE, self).__init__() \n",
    "                self.chart_features = chart_features\n",
    "                self.sequence_length = sequence_length \n",
    "                self.d_model = d_model \n",
    "                self.n_heads = n_heads \n",
    "                self.num_encoders = num_encoders \n",
    "                self.dain = DAIN_Layer(mode=\"full\", mean_lr=1e-06, gate_lr=10, scale_lr=0.001, input_dim=self.sequence_length)  \n",
    "                self.chart_embedder = nn.Sequential(\n",
    "                        nn.Linear(self.chart_features, d_model//2),\n",
    "                        nn.ReLU(), \n",
    "                        nn.Linear(d_model//2, d_model)\n",
    "                )\n",
    "                self.pos_encoder = PositionalEncoding(d_model=self.d_model) \n",
    "                self.encoder_layers = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.n_heads, batch_first=True)\n",
    "                self.transformer_encoder = nn.TransformerEncoder(self.encoder_layers, num_layers=self.num_encoders) \n",
    "        def forward(self, x): \n",
    "                x = self.dain(x) \n",
    "                x = self.chart_embedder(x) \n",
    "                x = self.pos_encoder(x) \n",
    "                x = self.transformer_encoder(x) \n",
    "                x = torch.mean(x, dim=1) \n",
    "                return x \n",
    "            \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")             \n",
    "checkpoint = torch.load(\"24_BTC_SIMCSE_val_loss_0.2324610533746513.pt\")\n",
    "            \n",
    "model = BTCSimCSE(chart_features=1, sequence_length=24, d_model=128, n_heads=8, num_encoders=6) \n",
    "model.load_state_dict(checkpoint) \n",
    "model.to(device)  \n",
    "model.eval() \n",
    "print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b48f0-a321-4132-8ebb-2a8b5737a146",
   "metadata": {},
   "source": [
    "### Load Chart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b9c1d2-67c5-4526-a8d8-cf7682aab158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c7654bc5ac4903a9a66d6f7f8e78c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"BTC_USDT-1h-12.json\") as f: \n",
    "        d = json.load(f) \n",
    "\n",
    "chart_df = pd.DataFrame(d) \n",
    "chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "\n",
    "def process(df): \n",
    "        binance = ccxt.binance() \n",
    "        dates = df[\"timestamp\"].values \n",
    "        timestamp = [] \n",
    "        for i in range(len(dates)):\n",
    "                date_string = binance.iso8601(int(dates[i])) \n",
    "                date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "                timestamp.append(date_string) \n",
    "        df[\"datetime\"] = timestamp\n",
    "        df = df.drop(columns={\"timestamp\"}) \n",
    "        return df \n",
    "\n",
    "chart_df = process(chart_df) \n",
    "\n",
    "hours, days, months, years = [],[],[],[] \n",
    "for dt in tqdm(chart_df[\"datetime\"]):\n",
    "        dtobj = pd.to_datetime(dt) \n",
    "        hour = dtobj.hour \n",
    "        day = dtobj.day \n",
    "        month = dtobj.month \n",
    "        year = dtobj.year \n",
    "        hours.append(hour) \n",
    "        days.append(day) \n",
    "        months.append(month) \n",
    "        years.append(year) \n",
    "\n",
    "chart_df[\"hours\"] = hours \n",
    "chart_df[\"days\"] = days  \n",
    "chart_df[\"months\"] = months \n",
    "chart_df[\"years\"] = years "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f394d3-515e-43a7-b349-aed729b15e15",
   "metadata": {},
   "source": [
    "### Stride 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f9ff55d-1a2f-4f7a-8ec5-77589f690481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3440389a26044a0ca9f49cc5b6a81941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "close = chart_df[\"close\"].values \n",
    "datetimes = chart_df[\"datetime\"].values \n",
    "\n",
    "strides = 10 \n",
    "seq_len = 24 \n",
    "M = 6 # forecast horizon \n",
    "start_date_chart_data = {} \n",
    "gt_chart_data = {} \n",
    "key_dates = [] \n",
    "for i in tqdm(range(0, len(datetimes)), position=0, leave=True):\n",
    "    dt_obj = datetime.strptime(str(datetimes[i]), \"%Y-%m-%d %H:%M:%S\")  \n",
    "    start_date_chart_data[dt_obj] = close[i:i+seq_len] \n",
    "    gt_chart_data[dt_obj] = close[i+seq_len:i+seq_len+M] \n",
    "    key_dates.append(dt_obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5a9094-92f2-4d10-903e-081a932877ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1c3615930f4d828cfaba95c93fa48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# embedding hash map \n",
    "embeddings = {} \n",
    "\n",
    "for i in tqdm(range(len(datetimes) - seq_len)): \n",
    "    dtobj = datetime.strptime(str(datetimes[i]), \"%Y-%m-%d %H:%M:%S\")\n",
    "    cur_close = close[i:i+seq_len] \n",
    "    cur_close = torch.tensor(cur_close).float() \n",
    "    cur_close = torch.reshape(cur_close, (-1, 24, 1)).to(device) \n",
    "    with torch.no_grad():\n",
    "        output = model(cur_close) \n",
    "    embeddings[dtobj] = output \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32030e56-04df-4c66-aa87-771c3e47beb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b4a53dd726400f82d2dc510aba68c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "initializing...:   0%|          | 0/46322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68225c3421994429a6caef41ebec521c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating:   0%|          | 0/46322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test index runs from 1000 - len(chart_df) \n",
    "\n",
    "topK = 3 # 5, 10 will be tested too \n",
    "\n",
    "simcse_aug = {}  # query date: list of topK similar dates (these are all start dates)  \n",
    "\n",
    "for i in tqdm(range(1000, len(datetimes) - seq_len), desc=\"initializing...\"): \n",
    "    dtobj = datetime.strptime(str(datetimes[i]), \"%Y-%m-%d %H:%M:%S\")\n",
    "    simcse_aug[dtobj] = [] \n",
    "\n",
    "\n",
    "for index in tqdm(range(1000, len(chart_df) - seq_len), position=0, leave=True, desc=\"calculating\"): \n",
    "    # query_close_price = close[index:index + seq_len] \n",
    "    query_date = datetimes[index] \n",
    "    query_dt_obj = datetime.strptime(str(query_date), \"%Y-%m-%d %H:%M:%S\") \n",
    "    \n",
    "    # candidate_close_prices, candidate_dates, candidates_future  = [], [], []   \n",
    "    candidate_dates = [] \n",
    "    for key, value in start_date_chart_data.items(): \n",
    "        if key + timedelta(hours=30) <= query_dt_obj: # 24 hours + next 6 hours \n",
    "            # candidate_close_prices.append(value) \n",
    "            # candidates_future.append(gt_chart_data[key])\n",
    "            candidate_dates.append(key) \n",
    "    \n",
    "    candidate_embeddings = [] \n",
    "    for i in range(len(candidate_dates)):\n",
    "        candidate_embeddings.append(embeddings[candidate_dates[i]])\n",
    "    candidate_embeddings = torch.cat(candidate_embeddings, dim=0) \n",
    "    \n",
    "    query_embedding = embeddings[query_dt_obj]\n",
    "    \n",
    "    query_embedding = query_embedding.detach().cpu().numpy() \n",
    "    candidate_embeddings = candidate_embeddings.detach().cpu().numpy() \n",
    "    sim_scores = cdist(query_embedding, candidate_embeddings, \"cosine\")[0] \n",
    "    ranks = np.argsort(sim_scores) \n",
    "    \n",
    "    for i in range(len(ranks[:topK])): \n",
    "        simcse_aug[query_dt_obj].append(candidate_dates[ranks[i]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61cf7433-135a-406a-b372-29cac4575765",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"simcse_aug.pkl\", \"wb\") as handle: \n",
    "    pickle.dump(simcse_aug, handle) \n",
    "    \n",
    "with open(\"simcse_aug.pkl\", \"rb\") as handle: \n",
    "    simcse_aug_saved = pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae26d3d-ad45-432b-b96e-85915e913653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-28 02:00:00 [datetime.datetime(2017, 9, 1, 4, 0), datetime.datetime(2017, 8, 28, 4, 0), datetime.datetime(2017, 8, 19, 22, 0)]\n"
     ]
    }
   ],
   "source": [
    "for key, value in simcse_aug_saved.items(): \n",
    "    print(key, value) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebd364-e595-47f3-85db-fc1ce246cefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fcaef-a7b4-4d96-8173-40200c1bdfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
